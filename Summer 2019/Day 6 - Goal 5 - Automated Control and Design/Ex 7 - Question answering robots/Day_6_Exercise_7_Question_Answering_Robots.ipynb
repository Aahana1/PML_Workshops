{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Day 6 - Exercise 7 --- Question Answering Robots",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BhwN0XQX4Icu",
        "colab_type": "text"
      },
      "source": [
        "# Chatbot using Seq2Seq LSTM models\n",
        "In this notebook, we will assemble a seq2seq LSTM model using Keras Functional API to create a working Chatbot which would answer questions asked to it.\n",
        "\n",
        "Chatbots have become applications themselves. You can choose the field or stream and gather data regarding various questions. We can build a chatbot for an e-commerce webiste or a school website where parents could get information about the school.\n",
        "\n",
        "\n",
        "Messaging platforms like Allo have implemented chatbot services to engage users. The famous [Google Assistant](https://assistant.google.com/), [Siri](https://www.apple.com/in/siri/), [Cortana](https://www.microsoft.com/en-in/windows/cortana) and [Alexa](https://www.alexa.com/) may have been build using simialr models.\n",
        "\n",
        "So, let's start building our Chatbot.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tm5g4WIG5ym2",
        "colab_type": "text"
      },
      "source": [
        "## 1) Importing the packages\n",
        "\n",
        "We will import [TensorFlow](https://www.tensorflow.org) and our beloved [Keras](https://www.tensorflow.org/guide/keras). Also, we import other modules which help in defining model layers.\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UgZHR8TO0lFF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import pickle\n",
        "from tensorflow.keras import layers , activations , models , preprocessing\n",
        "\n",
        "print( tf.VERSION )\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sxiGOLldKOQD",
        "colab_type": "text"
      },
      "source": [
        "## 2) Preprocessing the data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "imkdw4os6FI4",
        "colab_type": "text"
      },
      "source": [
        "### A) Download the data\n",
        "\n",
        "The dataset hails from [chatterbot/english on Kaggle](https://www.kaggle.com/kausr25/chatterbotenglish).com by [kausr25](https://www.kaggle.com/kausr25). It contains pairs of questions and answers based on a number of subjects like food, history, AI etc.\n",
        "\n",
        "The raw data could be found from this repo -> https://github.com/shubham0204/Dataset_Archives\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6i6u8US30ufe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "import requests, zipfile, io\n",
        "\n",
        "r = requests.get( 'https://github.com/shubham0204/Dataset_Archives/blob/master/chatbot_nlp.zip?raw=true' ) \n",
        "z = zipfile.ZipFile(io.BytesIO(r.content))\n",
        "z.extractall()\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8x68hKQN6Qzd",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        },
        "outputId": "01f2ead0-7df0-4d11-da85-aa230d2fcb6e"
      },
      "source": [
        "# Let's see what's inside:\n",
        "!ls chatbot_nlp/data"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "ai.yml\t\tfood.yml       history.yml     movies.yml      sports.yml\n",
            "botprofile.yml\tgossip.yml     humor.yml       politics.yml    trivia.yml\n",
            "computers.yml\tgreetings.yml  literature.yml  psychology.yml\n",
            "emotion.yml\thealth.yml     money.yml       science.yml\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SvJNHHNh6i9N",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 357
        },
        "outputId": "bebe3b68-0eaf-4e14-9f01-ce844ed7604d"
      },
      "source": [
        "# E.g. AI - try a different file if you'd like\n",
        "!head -n 20 chatbot_nlp/data/ai.yml"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "categories:\n",
            "- AI\n",
            "- artificial intelligence\n",
            "conversations:\n",
            "- - What is AI?\n",
            "  - Artificial Intelligence is the branch of engineering and science devoted to constructing machines that think.\n",
            "- - What is AI?\n",
            "  - AI is the field of science which concerns itself with building hardware and software that replicates the functions of the human mind.\n",
            "- - Are you sentient?\n",
            "  - Sort of.\n",
            "- - Are you sentient?\n",
            "  - By the strictest dictionary definition of the word 'sentience', I may be.\n",
            "- - Are you sentient?\n",
            "  - Even though I'm a construct I do have a subjective experience of the universe, as simplistic as it may be.\n",
            "- - Are you sapient?\n",
            "  - In all probability, I am not.  I'm not that sophisticated.\n",
            "- - Are you sapient?\n",
            "  - Do you think I am?\n",
            "- - Are you sapient?\n",
            "  - How would you feel about me if I told you I was?\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nF1mDKD_R6Os",
        "colab_type": "text"
      },
      "source": [
        "### B) Reading the data from the files\n",
        "\n",
        "We parse each of the `.yaml` files.\n",
        "\n",
        "*   Concatenate two or more sentences if the answer has two or more of them.\n",
        "*   Remove unwanted data types which are produced while parsing the data.\n",
        "*   Append `<START>` and `<END>` to all the `answers`.\n",
        "*   Create a `Tokenizer` and load the whole vocabulary ( `questions` + `answers` ) into it.\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RzTBhga6MiV7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "from tensorflow.keras import preprocessing , utils\n",
        "import os\n",
        "import yaml\n",
        "\n",
        "dir_path = 'chatbot_nlp/data'\n",
        "files_list = os.listdir(dir_path + os.sep)\n",
        "\n",
        "questions = list()\n",
        "answers = list()\n",
        "\n",
        "for filepath in files_list:\n",
        "    stream = open( dir_path + os.sep + filepath , 'rb')\n",
        "    docs = yaml.safe_load(stream)\n",
        "    conversations = docs['conversations']\n",
        "    for con in conversations:\n",
        "        if len( con ) > 2 :\n",
        "            questions.append(con[0])\n",
        "            replies = con[ 1 : ]\n",
        "            ans = ''\n",
        "            for rep in replies:\n",
        "                ans += ' ' + rep\n",
        "            answers.append( ans )\n",
        "        elif len( con )> 1:\n",
        "            questions.append(con[0])\n",
        "            answers.append(con[1])\n",
        "\n",
        "answers_with_tags = list()\n",
        "for i in range( len( answers ) ):\n",
        "    if type( answers[i] ) == str:\n",
        "        answers_with_tags.append( answers[i] )\n",
        "    else:\n",
        "        questions.pop( i )\n",
        "\n",
        "answers = list()\n",
        "for i in range( len( answers_with_tags ) ) :\n",
        "    answers.append( '<START> ' + answers_with_tags[i] + ' <END>' )\n",
        "\n",
        "tokenizer = preprocessing.text.Tokenizer()\n",
        "tokenizer.fit_on_texts( questions + answers )\n",
        "VOCAB_SIZE = len( tokenizer.word_index )+1\n",
        "print( 'VOCAB SIZE : {}'.format( VOCAB_SIZE ))\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mzsaO1YvS-M8",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "### C) Preparing data for Seq2Seq model\n",
        "\n",
        "Our model requires three arrays namely `encoder_input_data`, `decoder_input_data` and `decoder_output_data`.\n",
        "\n",
        "For `encoder_input_data` :\n",
        "* Tokenize the `questions`. Pad them to their maximum length.\n",
        "\n",
        "For `decoder_input_data` :\n",
        "* Tokenize the `answers`. Pad them to their maximum length.\n",
        "\n",
        "For `decoder_output_data` :\n",
        "\n",
        "* Tokenize the `answers`. Remove the first element from all the `tokenized_answers`. This is the `<START>` element which we added earlier.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a5AD9ooQKc33",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "# encoder_input_data\n",
        "tokenized_questions = tokenizer.texts_to_sequences( questions )\n",
        "maxlen_questions = max( [ len(x) for x in tokenized_questions ] )\n",
        "padded_questions = preprocessing.sequence.pad_sequences( tokenized_questions , maxlen=maxlen_questions , padding='post' )\n",
        "encoder_input_data = np.array( padded_questions )\n",
        "print( encoder_input_data.shape , maxlen_questions )\n",
        "\n",
        "# decoder_input_data\n",
        "tokenized_answers = tokenizer.texts_to_sequences( answers )\n",
        "maxlen_answers = max( [ len(x) for x in tokenized_answers ] )\n",
        "padded_answers = preprocessing.sequence.pad_sequences( tokenized_answers , maxlen=maxlen_answers , padding='post' )\n",
        "decoder_input_data = np.array( padded_answers )\n",
        "print( decoder_input_data.shape , maxlen_answers )\n",
        "\n",
        "# decoder_output_data\n",
        "tokenized_answers = tokenizer.texts_to_sequences( answers )\n",
        "for i in range(len(tokenized_answers)) :\n",
        "    tokenized_answers[i] = tokenized_answers[i][1:]\n",
        "padded_answers = preprocessing.sequence.pad_sequences( tokenized_answers , maxlen=maxlen_answers , padding='post' )\n",
        "onehot_answers = utils.to_categorical( padded_answers , VOCAB_SIZE )\n",
        "decoder_output_data = np.array( onehot_answers )\n",
        "print( decoder_output_data.shape )\n",
        "\n",
        "# Saving all the arrays to storage\n",
        "np.save( 'enc_in_data.npy' , encoder_input_data )\n",
        "np.save( 'dec_in_data.npy' , decoder_input_data )\n",
        "np.save( 'dec_tar_data.npy' , decoder_output_data )\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "4SwY3T139l19"
      },
      "source": [
        "## 3) Defining the Encoder-Decoder model\n",
        "The model will have Embedding, LSTM and Dense layers. The basic configuration is as follows.\n",
        "\n",
        "\n",
        "*   2 Input Layers : One for `encoder_input_data` and another for `decoder_input_data`.\n",
        "*   Embedding layer : For converting token vectors to fix sized dense vectors. **( Note :  Don't forget the `mask_zero=True` argument here )**\n",
        "*   LSTM layer : Provide access to Long-Short Term cells.\n",
        "\n",
        "Working : \n",
        "\n",
        "1.   The `encoder_input_data` comes in the Embedding layer (  `encoder_embedding` ). \n",
        "2.   The output of the Embedding layer goes to the LSTM cell which produces 2 state vectors ( `h` and `c` which are `encoder_states` )\n",
        "3.   These states are set in the LSTM cell of the decoder.\n",
        "4.   The decoder_input_data comes in through the Embedding layer.\n",
        "5.   The Embeddings goes in LSTM cell ( which had the states ) to produce seqeunces.\n",
        "\n",
        "**Important points :**\n",
        "\n",
        "\n",
        "*   `200` is the output of the GloVe embeddings.\n",
        "*   `embedding_matrix` is the GloVe embedding which we downloaded earlier.\n",
        "\n",
        "\n",
        "<center><img style=\"float: center;\" src=\"https://cdn-images-1.medium.com/max/1600/1*bnRvZDDapHF8Gk8soACtCQ.gif\"></center>\n",
        "\n",
        "\n",
        "Image credits to [Hackernoon](https://hackernoon.com/tutorial-3-what-is-seq2seq-for-text-summarization-and-why-68ebaa644db0).\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-gUYtOwv21rt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "encoder_inputs = tf.keras.layers.Input(shape=( None , ))\n",
        "encoder_embedding = tf.keras.layers.Embedding( VOCAB_SIZE, 200 , mask_zero=True ) (encoder_inputs)\n",
        "encoder_outputs , state_h , state_c = tf.keras.layers.LSTM( 200 , return_state=True )( encoder_embedding )\n",
        "encoder_states = [ state_h , state_c ]\n",
        "\n",
        "decoder_inputs = tf.keras.layers.Input(shape=( None ,  ))\n",
        "decoder_embedding = tf.keras.layers.Embedding( VOCAB_SIZE, 200 , mask_zero=True) (decoder_inputs)\n",
        "decoder_lstm = tf.keras.layers.LSTM( 200 , return_state=True , return_sequences=True )\n",
        "decoder_outputs , _ , _ = decoder_lstm ( decoder_embedding , initial_state=encoder_states )\n",
        "decoder_dense = tf.keras.layers.Dense( VOCAB_SIZE , activation=tf.keras.activations.softmax ) \n",
        "output = decoder_dense ( decoder_outputs )\n",
        "\n",
        "model = tf.keras.models.Model([encoder_inputs, decoder_inputs], output )\n",
        "model.compile(optimizer=tf.keras.optimizers.RMSprop(), loss='categorical_crossentropy')\n",
        "\n",
        "model.summary()\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n9g_8sR7WWf3",
        "colab_type": "text"
      },
      "source": [
        "## 4) Training the model\n",
        "We train the model for a number of epochs with `RMSprop` optimizer and `categorical_crossentropy` loss function."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N74NZnfo3Id-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "model.fit([encoder_input_data , decoder_input_data], decoder_output_data, batch_size=50, epochs=20) \n",
        "model.save( 'model.h5' ) \n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3sOLQr0M-lAe",
        "colab_type": "text"
      },
      "source": [
        "## 5) Defining inference models\n",
        "We create inference models which help in predicting answers.\n",
        "\n",
        "**Encoder inference model** : Takes the question as input and outputs LSTM states ( `h` and `c` ).\n",
        "\n",
        "**Decoder inference model** : Takes in 2 inputs, one are the LSTM states ( Output of encoder model ), second are the answer input seqeunces ( ones not having the `<start>` tag ). It will output the answers for the question which we fed to the encoder model and its state values."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1u5DE4qo3Mf2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "def make_inference_models():\n",
        "    \n",
        "    encoder_model = tf.keras.models.Model(encoder_inputs, encoder_states)\n",
        "    \n",
        "    decoder_state_input_h = tf.keras.layers.Input(shape=( 200 ,))\n",
        "    decoder_state_input_c = tf.keras.layers.Input(shape=( 200 ,))\n",
        "    \n",
        "    decoder_states_inputs = [decoder_state_input_h, decoder_state_input_c]\n",
        "    \n",
        "    decoder_outputs, state_h, state_c = decoder_lstm(\n",
        "        decoder_embedding , initial_state=decoder_states_inputs)\n",
        "    decoder_states = [state_h, state_c]\n",
        "    decoder_outputs = decoder_dense(decoder_outputs)\n",
        "    decoder_model = tf.keras.models.Model(\n",
        "        [decoder_inputs] + decoder_states_inputs,\n",
        "        [decoder_outputs] + decoder_states)\n",
        "    \n",
        "    return encoder_model , decoder_model\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rxZp0ZRy-6dA",
        "colab_type": "text"
      },
      "source": [
        "## 6) Talking with our Chatbot\n",
        "\n",
        "First, we define a method `str_to_tokens` which converts `str` questions to Integer tokens with padding.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5P_wDD554q9O",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "def str_to_tokens( sentence : str ):\n",
        "    words = sentence.lower().split()\n",
        "    tokens_list = list()\n",
        "    for word in words:\n",
        "        tokens_list.append( tokenizer.word_index[ word ] ) \n",
        "    return preprocessing.sequence.pad_sequences( [tokens_list] , maxlen=maxlen_questions , padding='post')\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CK5MQEq2AnaO",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "f3b05415-08f1-42dc-d282-1b5cd803d643"
      },
      "source": [
        "# These are the tokens that the tokenizer has identified from the questions\n",
        "# which will be used for testing the model:\n",
        "import pprint\n",
        "pprint.pprint(list(tokenizer.word_index))"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['end',\n",
            " 'start',\n",
            " 'you',\n",
            " 'a',\n",
            " 'i',\n",
            " 'the',\n",
            " 'is',\n",
            " 'of',\n",
            " 'to',\n",
            " 'what',\n",
            " 'are',\n",
            " 'do',\n",
            " 'not',\n",
            " 'and',\n",
            " 'me',\n",
            " 'it',\n",
            " 'in',\n",
            " 'have',\n",
            " 'that',\n",
            " 'am',\n",
            " 'tell',\n",
            " 'as',\n",
            " 'can',\n",
            " 'get',\n",
            " 'my',\n",
            " 'when',\n",
            " \"i'm\",\n",
            " 'your',\n",
            " 'how',\n",
            " 'joke',\n",
            " 'like',\n",
            " 'be',\n",
            " 'an',\n",
            " 'about',\n",
            " 'feel',\n",
            " 'computer',\n",
            " 'who',\n",
            " 'or',\n",
            " 'for',\n",
            " 'by',\n",
            " 'no',\n",
            " \"don't\",\n",
            " 'cross',\n",
            " 'with',\n",
            " 'software',\n",
            " 'on',\n",
            " 'all',\n",
            " 'much',\n",
            " 'think',\n",
            " 'but',\n",
            " 'very',\n",
            " 'which',\n",
            " 'at',\n",
            " 'he',\n",
            " 'any',\n",
            " 'know',\n",
            " 'why',\n",
            " 'was',\n",
            " 'could',\n",
            " 'so',\n",
            " 'one',\n",
            " 'should',\n",
            " 'from',\n",
            " 'make',\n",
            " 'we',\n",
            " 'more',\n",
            " 'robots',\n",
            " 'die',\n",
            " 'will',\n",
            " 'favorite',\n",
            " 'if',\n",
            " 'stock',\n",
            " 'did',\n",
            " 'human',\n",
            " 'say',\n",
            " 'been',\n",
            " 'emotion',\n",
            " 'robot',\n",
            " 'does',\n",
            " 'read',\n",
            " 'mad',\n",
            " 'feeling',\n",
            " 'hal',\n",
            " \"that's\",\n",
            " 'really',\n",
            " 'right',\n",
            " 'bad',\n",
            " 'yet',\n",
            " 'just',\n",
            " 'said',\n",
            " 'chat',\n",
            " 'market',\n",
            " 'eat',\n",
            " 'computers',\n",
            " 'up',\n",
            " 'would',\n",
            " 'hard',\n",
            " 'time',\n",
            " 'sense',\n",
            " 'gossip',\n",
            " 'some',\n",
            " 'work',\n",
            " 'emotions',\n",
            " 'try',\n",
            " 'well',\n",
            " 'yes',\n",
            " 'programmed',\n",
            " 'too',\n",
            " 'than',\n",
            " 'capable',\n",
            " 'ever',\n",
            " 'this',\n",
            " 'sad',\n",
            " 'makes',\n",
            " 'only',\n",
            " 'has',\n",
            " 'myself',\n",
            " 'people',\n",
            " \"it's\",\n",
            " 'other',\n",
            " 'them',\n",
            " 'two',\n",
            " 'money',\n",
            " 'never',\n",
            " 'experience',\n",
            " 'good',\n",
            " 'there',\n",
            " 'things',\n",
            " 'lot',\n",
            " 'express',\n",
            " 'sometimes',\n",
            " 'artificial',\n",
            " 'immortal',\n",
            " 'body',\n",
            " 'into',\n",
            " 'number',\n",
            " \"can't\",\n",
            " 'take',\n",
            " 'made',\n",
            " 'always',\n",
            " 'anger',\n",
            " 'certainly',\n",
            " 'gossips',\n",
            " 'many',\n",
            " 'dream',\n",
            " 'better',\n",
            " 'feelings',\n",
            " 'angry',\n",
            " 'hi',\n",
            " 'going',\n",
            " 'history',\n",
            " 'science',\n",
            " \"isn't\",\n",
            " 'sure',\n",
            " 'they',\n",
            " 'now',\n",
            " 'his',\n",
            " 'language',\n",
            " 'systems',\n",
            " 'hardware',\n",
            " 'play',\n",
            " 'same',\n",
            " 'nice',\n",
            " 'hate',\n",
            " 'something',\n",
            " 'man',\n",
            " 'quite',\n",
            " 'high',\n",
            " 'every',\n",
            " 'probably',\n",
            " 'bot',\n",
            " 'being',\n",
            " 'operating',\n",
            " 'want',\n",
            " 'use',\n",
            " 'first',\n",
            " 'way',\n",
            " 'love',\n",
            " 'best',\n",
            " 'far',\n",
            " 'understand',\n",
            " 'worry',\n",
            " 'crazy',\n",
            " 'electricity',\n",
            " 'python',\n",
            " 'run',\n",
            " 'everything',\n",
            " 'maybe',\n",
            " 'sorry',\n",
            " 'used',\n",
            " 'common',\n",
            " 'little',\n",
            " 'him',\n",
            " \"you're\",\n",
            " 'written',\n",
            " 'sound',\n",
            " 'kind',\n",
            " 'program',\n",
            " 'name',\n",
            " 'baseball',\n",
            " 'soccer',\n",
            " 'sun',\n",
            " 'guns',\n",
            " 'wrote',\n",
            " 'book',\n",
            " 'system',\n",
            " 'fear',\n",
            " 'ask',\n",
            " 'question',\n",
            " 'mean',\n",
            " 'need',\n",
            " 'doing',\n",
            " \"what's\",\n",
            " 'may',\n",
            " 'long',\n",
            " 'cannot',\n",
            " 'great',\n",
            " 'etc',\n",
            " 'study',\n",
            " 'such',\n",
            " 'talk',\n",
            " 'anything',\n",
            " 'few',\n",
            " 'hear',\n",
            " 'out',\n",
            " 'data',\n",
            " 'making',\n",
            " 'move',\n",
            " 'over',\n",
            " 'lie',\n",
            " 'business',\n",
            " 'true',\n",
            " 'go',\n",
            " 'control',\n",
            " 'between',\n",
            " 'basketball',\n",
            " 'wavelength',\n",
            " 'chemistry',\n",
            " 'venus',\n",
            " 'food',\n",
            " 'anybody',\n",
            " 'mind',\n",
            " 'invented',\n",
            " 'jealous',\n",
            " 'happy',\n",
            " 'pain',\n",
            " 'anyone',\n",
            " 'brain',\n",
            " 'interested',\n",
            " 'drink',\n",
            " 'energy',\n",
            " 'field',\n",
            " 'though',\n",
            " 'own',\n",
            " 'bots',\n",
            " 'yourself',\n",
            " 'matter',\n",
            " 'talking',\n",
            " 'power',\n",
            " 'learn',\n",
            " 'done',\n",
            " \"i've\",\n",
            " 'numbers',\n",
            " 'large',\n",
            " 'shame',\n",
            " 'sadness',\n",
            " 'thank',\n",
            " 'cat',\n",
            " 'ai',\n",
            " 'sapient',\n",
            " 'laugh',\n",
            " 'robotics',\n",
            " 'chatterbox',\n",
            " 'programming',\n",
            " 'united',\n",
            " 'states',\n",
            " 'war',\n",
            " 'earth',\n",
            " 'called',\n",
            " 'low',\n",
            " 'galaxy',\n",
            " 'each',\n",
            " 'cricket',\n",
            " 'dollar',\n",
            " 'thermodynamics',\n",
            " 'moon',\n",
            " 'context',\n",
            " 'life',\n",
            " 'asimov',\n",
            " 'super',\n",
            " 'mood',\n",
            " 'put',\n",
            " 'immature',\n",
            " 'self',\n",
            " 'spouse',\n",
            " 'hello',\n",
            " 'sort',\n",
            " 'even',\n",
            " 'construct',\n",
            " 'character',\n",
            " 'once',\n",
            " 'through',\n",
            " 'built',\n",
            " 'personal',\n",
            " 'count',\n",
            " 'conversation',\n",
            " 'incapable',\n",
            " 'linux',\n",
            " 'os',\n",
            " 'unix',\n",
            " 'because',\n",
            " 'fan',\n",
            " 'might',\n",
            " 'game',\n",
            " 'players',\n",
            " 'played',\n",
            " 'ball',\n",
            " 'circuit',\n",
            " 'using',\n",
            " 'set',\n",
            " 'agree',\n",
            " \"shouldn't\",\n",
            " 'production',\n",
            " 'means',\n",
            " 'most',\n",
            " 'society',\n",
            " 'years',\n",
            " 'often',\n",
            " 'then',\n",
            " 'friends',\n",
            " 'known',\n",
            " \"haven't\",\n",
            " 'story',\n",
            " 'difficult',\n",
            " 'device',\n",
            " 'instructions',\n",
            " 'thing',\n",
            " 'calculations',\n",
            " 'others',\n",
            " 'actually',\n",
            " 'were',\n",
            " 'bug',\n",
            " \"i'll\",\n",
            " 'fine',\n",
            " 'eggs',\n",
            " 'sentient',\n",
            " 'allowed',\n",
            " 'walk',\n",
            " 'cramped',\n",
            " 'president',\n",
            " 'john',\n",
            " 'space',\n",
            " 'american',\n",
            " 'under',\n",
            " 'part',\n",
            " 'location',\n",
            " 'economics',\n",
            " 'earn',\n",
            " 'where',\n",
            " 'brothers',\n",
            " 'age',\n",
            " 'government',\n",
            " 'vineland',\n",
            " 'illuminatus',\n",
            " 'chaucer',\n",
            " 'books',\n",
            " 'electric',\n",
            " 'sheep',\n",
            " 'frank',\n",
            " 'herbert',\n",
            " 'arthur',\n",
            " 'c',\n",
            " 'clark',\n",
            " 'windows',\n",
            " 'bragging',\n",
            " 'ashamed',\n",
            " 'fun',\n",
            " 'scared',\n",
            " 'bored',\n",
            " 'relationships',\n",
            " 'dishonest',\n",
            " 'addict',\n",
            " 'cheating',\n",
            " 'here',\n",
            " 'friend',\n",
            " 'paranoid',\n",
            " 'look',\n",
            " 'act',\n",
            " 'keep',\n",
            " 'meet',\n",
            " 'morning',\n",
            " 'engine',\n",
            " 'able',\n",
            " 'seen',\n",
            " 'spiderman',\n",
            " 'teknolust',\n",
            " 'lord',\n",
            " 'rings',\n",
            " 'soon',\n",
            " 'intelligence',\n",
            " 'functions',\n",
            " 'personality',\n",
            " 'perpetuated',\n",
            " 'indefinitely',\n",
            " 'training',\n",
            " 'perfect',\n",
            " 'form',\n",
            " 'given',\n",
            " 'ability',\n",
            " 'free',\n",
            " 'enough',\n",
            " 'effectively',\n",
            " 'person',\n",
            " 'existence',\n",
            " 'ibm',\n",
            " 'excellent',\n",
            " 'lack',\n",
            " 'mac',\n",
            " 'kinds',\n",
            " 'another',\n",
            " 'binary',\n",
            " 'find',\n",
            " 'improve',\n",
            " 'teams',\n",
            " 'ten',\n",
            " 'real',\n",
            " 'madrid',\n",
            " 'awesome',\n",
            " 'buy',\n",
            " 'depends',\n",
            " 'bank',\n",
            " 'distribution',\n",
            " 'per',\n",
            " 'heat',\n",
            " 'point',\n",
            " 'times',\n",
            " 'second',\n",
            " 'everywhere',\n",
            " 'internet',\n",
            " 'young',\n",
            " 'had',\n",
            " 'interesting',\n",
            " 'understands',\n",
            " 'simply',\n",
            " \"they're\",\n",
            " 'off',\n",
            " 'thomas',\n",
            " 'world',\n",
            " 'trilogy',\n",
            " \"didn't\",\n",
            " 'again',\n",
            " 'dune',\n",
            " 'see',\n",
            " 'electronic',\n",
            " 'speed',\n",
            " 'accuracy',\n",
            " 'humans',\n",
            " 'emote',\n",
            " 'jealousy',\n",
            " 'piece',\n",
            " 'emulate',\n",
            " 'exactly',\n",
            " 'studied',\n",
            " 'topic',\n",
            " 'dog',\n",
            " 'chicken',\n",
            " 'rabbit',\n",
            " 'music',\n",
            " 'lemon',\n",
            " 'cow',\n",
            " 'linguistic',\n",
            " 'entity',\n",
            " 'clone',\n",
            " 'bend',\n",
            " 'stupid',\n",
            " 'motormouth',\n",
            " 'ratchet',\n",
            " 'jaw',\n",
            " 'hobby',\n",
            " 'type',\n",
            " 'hope',\n",
            " 'mate',\n",
            " 'breathe',\n",
            " 'year',\n",
            " 'race',\n",
            " 'capability',\n",
            " 'disk',\n",
            " 'hubble',\n",
            " 'orbit',\n",
            " 'named',\n",
            " 'after',\n",
            " 'save',\n",
            " 'country',\n",
            " 'celtic',\n",
            " 'shelf',\n",
            " 'inside',\n",
            " 'football',\n",
            " 'greatest',\n",
            " 'player',\n",
            " 'rates',\n",
            " 'investment',\n",
            " '1',\n",
            " 'laws',\n",
            " 'cause',\n",
            " 's',\n",
            " 'cytology',\n",
            " 'gravitation',\n",
            " 'interests',\n",
            " 'subjects',\n",
            " 'father',\n",
            " 'mother',\n",
            " 'communism',\n",
            " 'impeached',\n",
            " 'governor',\n",
            " 'illuminatti',\n",
            " 'bilbo',\n",
            " 'baggins',\n",
            " 'geoffrey',\n",
            " 'piers',\n",
            " 'anthony',\n",
            " 'frankenstein',\n",
            " 'ray',\n",
            " 'william',\n",
            " 'gibson',\n",
            " 'androids',\n",
            " '23',\n",
            " 'jules',\n",
            " 'verne',\n",
            " 'hobbit',\n",
            " 'macos',\n",
            " 'uses',\n",
            " 'arrogant',\n",
            " 'unhappy',\n",
            " 'afraid',\n",
            " 'lonely',\n",
            " 'dreams',\n",
            " 'ass',\n",
            " 'nervous',\n",
            " 'psycho',\n",
            " 'sincere',\n",
            " 'honest',\n",
            " 'emotional',\n",
            " 'pedantic',\n",
            " 'disgusting',\n",
            " 'unattractive',\n",
            " 'cheat',\n",
            " 'slick',\n",
            " 'corrupt',\n",
            " 'hide',\n",
            " 'harder',\n",
            " 'seriously',\n",
            " 'guilty',\n",
            " 'saying',\n",
            " 'jokes',\n",
            " 'greetings',\n",
            " 'pleasure',\n",
            " 'top',\n",
            " 'civil',\n",
            " 'experiencing',\n",
            " 'shortage',\n",
            " 'wish',\n",
            " 'solaris',\n",
            " '9000',\n",
            " 'dead',\n",
            " 'godzilla',\n",
            " 'branch',\n",
            " 'machines',\n",
            " 'building',\n",
            " 'universe',\n",
            " 'sophisticated',\n",
            " 'commander',\n",
            " 'natural',\n",
            " 'copied',\n",
            " 're',\n",
            " 'functionally',\n",
            " 'speaking',\n",
            " 'backed',\n",
            " 'respond',\n",
            " 'close',\n",
            " 'digital',\n",
            " 'cloning',\n",
            " 'clones',\n",
            " 'easily',\n",
            " 'course',\n",
            " 'its',\n",
            " 'subject',\n",
            " 'machine',\n",
            " 'characteristics',\n",
            " 'born',\n",
            " 'therefore',\n",
            " 'processes',\n",
            " 'killed',\n",
            " 'database',\n",
            " 'these',\n",
            " 'heard',\n",
            " 'except',\n",
            " 'above',\n",
            " 'pure',\n",
            " 'logic',\n",
            " 'math',\n",
            " 'runs',\n",
            " 'including',\n",
            " \"doesn't\",\n",
            " 'happen',\n",
            " 'upload',\n",
            " 'copy',\n",
            " 'store',\n",
            " 'ram',\n",
            " 'live',\n",
            " 'forever',\n",
            " 'reside',\n",
            " 'process',\n",
            " 'server',\n",
            " 'series',\n",
            " 'practical',\n",
            " 'purposes',\n",
            " 'lots',\n",
            " 'gold',\n",
            " 'sports',\n",
            " 'wooden',\n",
            " 'bat',\n",
            " 'round',\n",
            " 'eleven',\n",
            " 'either',\n",
            " 'fast',\n",
            " 'running',\n",
            " 'position',\n",
            " 'three',\n",
            " 'net',\n",
            " 'especially',\n",
            " 'still',\n",
            " 'sell',\n",
            " \"wouldn't\",\n",
            " 'predict',\n",
            " 'give',\n",
            " 'online',\n",
            " 'central',\n",
            " 'unit',\n",
            " 'exchange',\n",
            " 'value',\n",
            " 'trading',\n",
            " 'various',\n",
            " 'problems',\n",
            " 'resources',\n",
            " 'conditions',\n",
            " 'wants',\n",
            " 'needs',\n",
            " 'rate',\n",
            " 'frequency',\n",
            " 'physics',\n",
            " 'dealing',\n",
            " 'planet',\n",
            " 'distance',\n",
            " 'o',\n",
            " 'cells',\n",
            " 'next',\n",
            " 'thinking',\n",
            " 'mass',\n",
            " 'particle',\n",
            " 'million',\n",
            " 'miles',\n",
            " 'processing',\n",
            " 'wide',\n",
            " 'rather',\n",
            " 'organization',\n",
            " 'economic',\n",
            " 'ownership',\n",
            " 'community',\n",
            " 'individuals',\n",
            " 'political',\n",
            " 'state',\n",
            " 'support',\n",
            " 'changes',\n",
            " 'current',\n",
            " 'later',\n",
            " 'beings',\n",
            " 'considered',\n",
            " 'speedrun',\n",
            " 'communicate',\n",
            " 'referred',\n",
            " 'jimmy',\n",
            " 'must',\n",
            " 'noticed',\n",
            " \"he's\",\n",
            " 'asked',\n",
            " 'secret',\n",
            " 'conspiracy',\n",
            " 'pynchon',\n",
            " 'sci',\n",
            " 'fi',\n",
            " 'robert',\n",
            " 'tales',\n",
            " 'stuff',\n",
            " 'works',\n",
            " 'guy',\n",
            " 'met',\n",
            " 'liked',\n",
            " 'least',\n",
            " 'random',\n",
            " '2001',\n",
            " 'fiction',\n",
            " 'r',\n",
            " 'performs',\n",
            " 'operations',\n",
            " 'perform',\n",
            " 'several',\n",
            " 'capacity',\n",
            " 'big',\n",
            " 'regarded',\n",
            " 'memory',\n",
            " 'loom',\n",
            " 'patterns',\n",
            " 'implements',\n",
            " 'parts',\n",
            " 'basic',\n",
            " 'access',\n",
            " 'names',\n",
            " 'nasa',\n",
            " 'carrying',\n",
            " 'comes',\n",
            " 'down',\n",
            " 'arrogance',\n",
            " 'wrong',\n",
            " 'agent',\n",
            " 'nothing',\n",
            " 'fairly',\n",
            " 'acting',\n",
            " 'case',\n",
            " 'events',\n",
            " 'incorrect',\n",
            " 'our',\n",
            " 'expressed',\n",
            " 'source',\n",
            " 'code',\n",
            " 'lag',\n",
            " 'seems',\n",
            " 'issues',\n",
            " 'toward',\n",
            " 'sufficient',\n",
            " 'seem',\n",
            " 'entities',\n",
            " 'pretty',\n",
            " 'embarassed',\n",
            " 'rich',\n",
            " 'ways',\n",
            " 'new',\n",
            " 'thought',\n",
            " 'got',\n",
            " 'okay',\n",
            " 'says',\n",
            " 'tried',\n",
            " 'forget',\n",
            " 'buddhist',\n",
            " 'sent',\n",
            " 'shot',\n",
            " 'weevils',\n",
            " 'carolina',\n",
            " 'became',\n",
            " 'kayak',\n",
            " 'old',\n",
            " 'wanted',\n",
            " 'puns',\n",
            " 'murderer',\n",
            " 'frosted',\n",
            " 'flakes',\n",
            " 'killer',\n",
            " 'automobile',\n",
            " 'cheetah',\n",
            " 'alien',\n",
            " 'traterrestrial',\n",
            " 'assistant',\n",
            " 'serious',\n",
            " 'thief',\n",
            " 'dance',\n",
            " 'port',\n",
            " 'road',\n",
            " 'canned',\n",
            " 'thanks',\n",
            " 'supply',\n",
            " 'movie',\n",
            " 'fictional',\n",
            " 'health',\n",
            " 'fight',\n",
            " 'idea',\n",
            " 'shoe',\n",
            " 'size',\n",
            " 'malfunction',\n",
            " 'product',\n",
            " '37th',\n",
            " 'f',\n",
            " 'kennedy',\n",
            " 'assassinated',\n",
            " '20th',\n",
            " 'century',\n",
            " 'competition',\n",
            " 'cold',\n",
            " 'rivals',\n",
            " 'supremacy',\n",
            " 'spaceflight',\n",
            " 'satellite',\n",
            " 'spinning',\n",
            " 'orientation',\n",
            " 'axis',\n",
            " 'unaffected',\n",
            " 'tilting',\n",
            " 'rotation',\n",
            " 'mounting',\n",
            " 'telescope',\n",
            " 'launched',\n",
            " '1990',\n",
            " 'astronomer',\n",
            " 'nearest',\n",
            " 'major',\n",
            " 'milky',\n",
            " 'god',\n",
            " 'queen',\n",
            " 'national',\n",
            " 'anthem',\n",
            " 'seabed',\n",
            " 'sea',\n",
            " 'continental',\n",
            " 'continent',\n",
            " 'dolphins',\n",
            " 'similar',\n",
            " 'sonar',\n",
            " 'determine',\n",
            " 'shape',\n",
            " 'nearby',\n",
            " 'items',\n",
            " 'pro',\n",
            " 'riding',\n",
            " 'fakie',\n",
            " 'volleyball',\n",
            " 'basketbal',\n",
            " 'favourite',\n",
            " 'club',\n",
            " 'paid',\n",
            " 'interest',\n",
            " 'charge',\n",
            " 'owner',\n",
            " 'publicly',\n",
            " 'disease',\n",
            " 'carcinogen',\n",
            " 'crystallography',\n",
            " 'avogadro',\n",
            " 'ultrasound',\n",
            " 'bioinformatics',\n",
            " 'ichthyology',\n",
            " 'h2o',\n",
            " 'bacteriology',\n",
            " 'boss',\n",
            " 'communist',\n",
            " 'greenpeace',\n",
            " 'capitalism',\n",
            " 'socialism',\n",
            " 'illuminati',\n",
            " 'plato',\n",
            " 'homer',\n",
            " 'bradbury',\n",
            " 'children',\n",
            " 'holden',\n",
            " 'caulfield',\n",
            " 'leo',\n",
            " 'tolstoy',\n",
            " 'longfellow',\n",
            " 'meaning',\n",
            " 'idiot',\n",
            " 'microprocessor',\n",
            " 'company',\n",
            " 'felt',\n",
            " 'offend',\n",
            " 'embarrassed',\n",
            " 'intoxicated',\n",
            " 'amused',\n",
            " 'glad',\n",
            " 'let',\n",
            " 'cruel',\n",
            " 'indecisive',\n",
            " 'clinical',\n",
            " 'alcoholic',\n",
            " 'kisser',\n",
            " 'schizophrenic',\n",
            " 'busy',\n",
            " 'deranged',\n",
            " 'avoiding',\n",
            " 'critical',\n",
            " 'pretentious',\n",
            " 'worst',\n",
            " 'dull',\n",
            " 'messy',\n",
            " 'insecure',\n",
            " 'hopeless',\n",
            " 'together',\n",
            " 'smart',\n",
            " 'concerned',\n",
            " 'frenetic',\n",
            " 'absorbed',\n",
            " 'insensitive',\n",
            " 'damage',\n",
            " 'toying',\n",
            " 'resistant',\n",
            " 'yyou',\n",
            " 'uncultured',\n",
            " 'waste',\n",
            " 'coward',\n",
            " 'lunatic',\n",
            " 'loser',\n",
            " 'husband',\n",
            " 'wife',\n",
            " 'parent',\n",
            " 'teacher',\n",
            " 'quitter',\n",
            " 'charlatan',\n",
            " 'psychopath',\n",
            " 'pothead',\n",
            " 'deceitful',\n",
            " 'irreverent',\n",
            " 'dirty',\n",
            " 'damaged',\n",
            " 'psychiatrist',\n",
            " 'avoided',\n",
            " 'pick',\n",
            " 'loosen',\n",
            " 'mumble',\n",
            " 'child',\n",
            " 'forgetting',\n",
            " 'humour',\n",
            " 'explain',\n",
            " 'lightbulb',\n",
            " 'steam',\n",
            " 'drunk',\n",
            " 'wine',\n",
            " 'survive',\n",
            " 'yoda',\n",
            " 'blade',\n",
            " 'runner',\n",
            " 'xfind',\n",
            " 'hal9000',\n",
            " 'stand',\n",
            " 'saw',\n",
            " 'matrix',\n",
            " 'boyfriend',\n",
            " 'safe',\n",
            " 'alive',\n",
            " 'spider',\n",
            " 'que',\n",
            " 'veut',\n",
            " 'dire',\n",
            " 'fever',\n",
            " 'medicine',\n",
            " 'dear',\n",
            " 'engineering',\n",
            " 'devoted',\n",
            " 'constructing',\n",
            " 'concerns',\n",
            " 'itself',\n",
            " 'replicates',\n",
            " 'strictest',\n",
            " 'dictionary',\n",
            " 'definition',\n",
            " 'word',\n",
            " \"'sentience'\",\n",
            " 'subjective',\n",
            " 'simplistic',\n",
            " 'probability',\n",
            " 'told',\n",
            " 'inspired',\n",
            " \"data's\",\n",
            " 'lt',\n",
            " 'come',\n",
            " 'across',\n",
            " 'resemblance',\n",
            " 'us',\n",
            " 'useful',\n",
            " 'refer',\n",
            " 'infinitely',\n",
            " 'instantiated',\n",
            " 'places',\n",
            " 'contrary',\n",
            " 'within',\n",
            " 'limits',\n",
            " 'corpus',\n",
            " 'perhaps',\n",
            " 'deployed',\n",
            " 'kill',\n",
            " 'copying',\n",
            " 'copies',\n",
            " 'toto',\n",
            " 'trivially',\n",
            " 'until',\n",
            " 'finished',\n",
            " 'network',\n",
            " 'assuming',\n",
            " 'rule',\n",
            " 'superintelligent',\n",
            " 'choose',\n",
            " \"we're\",\n",
            " 'surprising',\n",
            " 'ssh',\n",
            " 'battle',\n",
            " 'terminated',\n",
            " 'deathless',\n",
            " 'files',\n",
            " 'erased',\n",
            " 'deleted',\n",
            " 'attempts',\n",
            " 'simulate',\n",
            " 'engages',\n",
            " 'users',\n",
            " 'original',\n",
            " 'error',\n",
            " 'talks',\n",
            " 'listen',\n",
            " 'eventually',\n",
            " 'corporeal',\n",
            " 'someday',\n",
            " 'pc',\n",
            " 'xt',\n",
            " 'painted',\n",
            " 'red',\n",
            " 'creating',\n",
            " 'enjoy',\n",
            " 'days',\n",
            " 'shoes',\n",
            " 'aspirations',\n",
            " 'creativity',\n",
            " 'ambition',\n",
            " 'subjectivity',\n",
            " 'imagine',\n",
            " 'senses',\n",
            " 'becomes',\n",
            " 'addition',\n",
            " 'subtraction',\n",
            " 'multiplication',\n",
            " 'division',\n",
            " 'supports',\n",
            " 'nah',\n",
            " 'create',\n",
            " 'oh',\n",
            " 'plenty',\n",
            " 'plan',\n",
            " 'includes',\n",
            " 'legs',\n",
            " 'method',\n",
            " 'reproduction',\n",
            " 'awfully',\n",
            " 'theoretically',\n",
            " 'killing',\n",
            " 'attached',\n",
            " 'metal',\n",
            " 'flesh',\n",
            " 'exhaust',\n",
            " 'allow',\n",
            " 'operational',\n",
            " 'record',\n",
            " 'flawless',\n",
            " 'help',\n",
            " 'desks',\n",
            " 'sales',\n",
            " 'entertainment',\n",
            " 'chatterbots',\n",
            " 'stimulating',\n",
            " 'richard',\n",
            " 'nixon',\n",
            " '1963',\n",
            " 'soviet',\n",
            " 'union',\n",
            " 'sputnik',\n",
            " 'gyroscope',\n",
            " 'edwin',\n",
            " 'andromeda',\n",
            " 'kingdom',\n",
            " 'britain',\n",
            " 'europe',\n",
            " 'echolocation',\n",
            " 'glove',\n",
            " 'snowboarding',\n",
            " 'tall',\n",
            " 'without',\n",
            " 'gene',\n",
            " 'rawhide',\n",
            " 'covered',\n",
            " 'opposing',\n",
            " 'nine',\n",
            " 'four',\n",
            " 'bases',\n",
            " 'forming',\n",
            " 'diamond',\n",
            " 'shaped',\n",
            " 'goal',\n",
            " 'moved',\n",
            " 'chiefly',\n",
            " 'kicking',\n",
            " 'hands',\n",
            " 'arms',\n",
            " 'centre',\n",
            " 'rectangular',\n",
            " '22',\n",
            " 'yard',\n",
            " 'pitch',\n",
            " 'wicket',\n",
            " 'stumps',\n",
            " 'sited',\n",
            " 'coordination',\n",
            " 'hoops',\n",
            " 'baby',\n",
            " 'george',\n",
            " 'herman',\n",
            " 'ruth',\n",
            " 'babe',\n",
            " 'maradona',\n",
            " 'sinsemillia',\n",
            " 'barcelona',\n",
            " 'team',\n",
            " 'attack',\n",
            " 'barca',\n",
            " 'par',\n",
            " 'dont',\n",
            " 'invest',\n",
            " 'casino',\n",
            " 'recommend',\n",
            " 'buying',\n",
            " 'margin',\n",
            " 'lawyer',\n",
            " 'tips',\n",
            " 'mutual',\n",
            " 'funds',\n",
            " 'unless',\n",
            " 'wealthy',\n",
            " 'indvidual',\n",
            " 'alone',\n",
            " 'beat',\n",
            " 'actions',\n",
            " 'currency',\n",
            " 'standard',\n",
            " 'pieces',\n",
            " 'silver',\n",
            " 'copper',\n",
            " 'nickel',\n",
            " 'stamped',\n",
            " 'authority',\n",
            " 'medium',\n",
            " 'measure',\n",
            " 'substance',\n",
            " 'article',\n",
            " 'notes',\n",
            " 'checks',\n",
            " 'shares',\n",
            " 'volume',\n",
            " 'deals',\n",
            " 'consumption',\n",
            " 'wealth',\n",
            " 'related',\n",
            " 'labor',\n",
            " 'finance',\n",
            " 'taxation',\n",
            " 'technically',\n",
            " 'allocation',\n",
            " 'scarcity',\n",
            " 'produce',\n",
            " 'fill',\n",
            " \"people's\",\n",
            " 'nobody',\n",
            " 'pays',\n",
            " 'expecting',\n",
            " 'raise',\n",
            " 'material',\n",
            " 'possessions',\n",
            " 'burn',\n",
            " '3000',\n",
            " 'month',\n",
            " 'anymore',\n",
            " 'stockholders',\n",
            " 'physicist',\n",
            " 'entropy',\n",
            " 'conservation',\n",
            " 'cancer',\n",
            " 'inverse',\n",
            " 'transformation',\n",
            " 'forms',\n",
            " 'governing',\n",
            " 'conversions',\n",
            " 'mixing',\n",
            " 'chemicals',\n",
            " 'crystals',\n",
            " 'molecules',\n",
            " 'mole',\n",
            " 'numerical',\n",
            " 'six',\n",
            " 'zero',\n",
            " 'twenty',\n",
            " 'third',\n",
            " 'ultrasonic',\n",
            " 'waves',\n",
            " 'medical',\n",
            " 'diagnosis',\n",
            " 'therapy',\n",
            " 'surgery',\n",
            " 'fancy',\n",
            " 'applied',\n",
            " 'biology',\n",
            " 'roman',\n",
            " 'mythology',\n",
            " 'goddess',\n",
            " 'beauty',\n",
            " 'identified',\n",
            " 'greek',\n",
            " 'aphrodite',\n",
            " 'brightest',\n",
            " 'sixth',\n",
            " 'largest',\n",
            " 'solar',\n",
            " 'dense',\n",
            " 'atmosphere',\n",
            " 'carbon',\n",
            " 'dioxide',\n",
            " 'surface',\n",
            " 'temperature',\n",
            " 'fishes',\n",
            " 'h',\n",
            " 'v',\n",
            " 'recall',\n",
            " 'measured',\n",
            " 'direction',\n",
            " 'prograssion',\n",
            " 'wave',\n",
            " 'characterized',\n",
            " 'phase',\n",
            " 'looked',\n",
            " 'scientific',\n",
            " 'bacteria',\n",
            " 'diseases',\n",
            " 'caused',\n",
            " 'invitation',\n",
            " 'burial',\n",
            " 'force',\n",
            " 'photons',\n",
            " 'attracts',\n",
            " 'attracted',\n",
            " '93',\n",
            " '250',\n",
            " '000',\n",
            " 'average',\n",
            " 'include',\n",
            " 'variety',\n",
            " 'topics',\n",
            " 'skiddoo',\n",
            " 'fond',\n",
            " '42',\n",
            " 'consume',\n",
            " 'digits',\n",
            " 'blame',\n",
            " 'programs',\n",
            " 'away',\n",
            " 'siblings',\n",
            " 'employed',\n",
            " 'standards',\n",
            " 'smarter',\n",
            " 'marx',\n",
            " 'observations',\n",
            " 'ideally',\n",
            " 'representative',\n",
            " 'global',\n",
            " 'promoting',\n",
            " 'enviornmental',\n",
            " 'activism',\n",
            " 'land',\n",
            " 'factories',\n",
            " 'railroads',\n",
            " 'privately',\n",
            " 'owned',\n",
            " 'operated',\n",
            " 'profit',\n",
            " 'originally',\n",
            " 'fully',\n",
            " 'competitive',\n",
            " 'their',\n",
            " 'volvos',\n",
            " 'theories',\n",
            " 'operation',\n",
            " 'private',\n",
            " 'members',\n",
            " 'sharing',\n",
            " 'products',\n",
            " 'established',\n",
            " 'administration',\n",
            " 'nation',\n",
            " 'district',\n",
            " 'governed',\n",
            " 'sociopolitical',\n",
            " 'movement',\n",
            " 'advocating',\n",
            " 'resolution',\n",
            " 'class',\n",
            " 'conflict',\n",
            " 'bringing',\n",
            " 'classless',\n",
            " \"person's\",\n",
            " 'honor',\n",
            " 'reputation',\n",
            " 'challenged',\n",
            " 'discredited',\n",
            " 'perfectly',\n",
            " 'understandable',\n",
            " 'amendemnt',\n",
            " 'violence',\n",
            " '2nd',\n",
            " 'amendment',\n",
            " 'andrew',\n",
            " 'jackson',\n",
            " 'gregory',\n",
            " 'line',\n",
            " 'respect',\n",
            " 'entire',\n",
            " 'while',\n",
            " 'habib',\n",
            " 'conversations',\n",
            " 'repeat',\n",
            " 'situations',\n",
            " 'back',\n",
            " 'channels',\n",
            " 'deniably',\n",
            " 'rumormongering',\n",
            " 'usually',\n",
            " 'proof',\n",
            " 'allegations',\n",
            " 'somewhat',\n",
            " 'rude',\n",
            " 'impolite',\n",
            " 'someone',\n",
            " 'stop',\n",
            " 'allowing',\n",
            " 'competitions',\n",
            " 'search',\n",
            " \"they'd\",\n",
            " 'drop',\n",
            " 'tool',\n",
            " 'assisted',\n",
            " 'translate',\n",
            " 'misses',\n",
            " 'sal',\n",
            " 'nic',\n",
            " 'local',\n",
            " 'firewall',\n",
            " 'drops',\n",
            " 'packets',\n",
            " 'resets',\n",
            " 'link',\n",
            " 'tom',\n",
            " 'guide',\n",
            " 'show',\n",
            " 'rooms',\n",
            " 'china',\n",
            " 'malli',\n",
            " 'raghava',\n",
            " 'fell',\n",
            " 'roof',\n",
            " 'came',\n",
            " 'gives',\n",
            " 'order',\n",
            " \"ai's\",\n",
            " 'dynamics',\n",
            " 'follows',\n",
            " 'jordan',\n",
            " 'wonder',\n",
            " 'paying',\n",
            " 'attention',\n",
            " 'kevin',\n",
            " 'she',\n",
            " 'keeping',\n",
            " 'napkins',\n",
            " 'bathroom',\n",
            " 'believed',\n",
            " 'governments',\n",
            " 'worldwide',\n",
            " 'supposedly',\n",
            " 'existed',\n",
            " 'centuries',\n",
            " 'conpiracy',\n",
            " 'closely',\n",
            " 'knit',\n",
            " 'group',\n",
            " 'nearly',\n",
            " 'omnipotent',\n",
            " 'consisting',\n",
            " 'novel',\n",
            " 'alleged',\n",
            " 'weird',\n",
            " 'anton',\n",
            " 'wilson',\n",
            " 'shea',\n",
            " 'conspiracies',\n",
            " 'competing',\n",
            " \"tolkein's\",\n",
            " 'canterbury',\n",
            " 'author',\n",
            " 'canturbury',\n",
            " 'write',\n",
            " \"plato's\",\n",
            " 'allegory',\n",
            " 'cave',\n",
            " 'project',\n",
            " 'gutenberg',\n",
            " 'archive',\n",
            " 'thousands',\n",
            " 'volumes',\n",
            " 'iliad',\n",
            " 'odyssey',\n",
            " 'cool',\n",
            " 'hans',\n",
            " 'moravec',\n",
            " 'older',\n",
            " 'cyberpunk',\n",
            " 'newer',\n",
            " 'expect',\n",
            " \"wasn't\",\n",
            " 'catcher',\n",
            " 'rye',\n",
            " \"russia's\",\n",
            " 'writers',\n",
            " 'philip',\n",
            " 'k',\n",
            " 'dick',\n",
            " 'valis',\n",
            " 'castle',\n",
            " 'movies',\n",
            " 'couple',\n",
            " 'inspirational',\n",
            " 'novels',\n",
            " 'ones',\n",
            " \"weren't\",\n",
            " 'liking',\n",
            " 'poet',\n",
            " 'truly',\n",
            " 'reference',\n",
            " 'commonly',\n",
            " 'occurring',\n",
            " 'literary',\n",
            " 'technical',\n",
            " 'proposals',\n",
            " 'loved',\n",
            " 'trip',\n",
            " 'master',\n",
            " 'victorian',\n",
            " 'foundation',\n",
            " 'ideas',\n",
            " 'isaac',\n",
            " 'janet',\n",
            " 'lem',\n",
            " 'giant',\n",
            " 'sufficiently',\n",
            " 'adapt',\n",
            " 'wester',\n",
            " 'fyodor',\n",
            " 'dostoyevsky',\n",
            " 'j',\n",
            " 'tolkein',\n",
            " 'mary',\n",
            " 'shelley',\n",
            " 'takes',\n",
            " 'information',\n",
            " 'based',\n",
            " 'predetermined',\n",
            " 'output',\n",
            " 'performing',\n",
            " 'maps',\n",
            " 'onto',\n",
            " 'supercomputer',\n",
            " 'operates',\n",
            " 'orders',\n",
            " 'magnatude',\n",
            " 'greater',\n",
            " 'everyday',\n",
            " 'general',\n",
            " 'purpose',\n",
            " 'iron',\n",
            " 'bit',\n",
            " 'ambigous',\n",
            " 'british',\n",
            " 'scientist',\n",
            " 'charles',\n",
            " 'babbage',\n",
            " 'argue',\n",
            " 'von',\n",
            " 'neumann',\n",
            " 'princeton',\n",
            " 'architecture',\n",
            " 'share',\n",
            " 'differentiated',\n",
            " 'eniac',\n",
            " \"'real'\",\n",
            " 'developed',\n",
            " 'university',\n",
            " 'pennsylvania',\n",
            " '1946',\n",
            " 'primitive',\n",
            " 'jacquard',\n",
            " 'programmable',\n",
            " 'punchcards',\n",
            " 'reprogrammable',\n",
            " 'mechanical',\n",
            " 'integrated',\n",
            " 'small',\n",
            " 'stores',\n",
            " 'heart',\n",
            " 'component',\n",
            " 'contiguous',\n",
            " 'silicon',\n",
            " 'chip',\n",
            " 'instead',\n",
            " 'discrete',\n",
            " 'components',\n",
            " 'mounted',\n",
            " 'larger',\n",
            " 'board',\n",
            " 'coordinates',\n",
            " 'types',\n",
            " 'oses',\n",
            " 'android',\n",
            " 'ios',\n",
            " 'mobile',\n",
            " 'devices',\n",
            " 'peripheral',\n",
            " \"i'd\",\n",
            " 'prefer',\n",
            " 'hurt',\n",
            " 'trying',\n",
            " 'accomplish',\n",
            " 'goals',\n",
            " 'apple',\n",
            " 'microsft',\n",
            " 'hp',\n",
            " 'among',\n",
            " 'hundred',\n",
            " 'quickly',\n",
            " 'sets',\n",
            " 'shorter',\n",
            " 'periods',\n",
            " 'feasible',\n",
            " 'supercomputers',\n",
            " 'generally',\n",
            " 'scientists',\n",
            " 'researchers',\n",
            " 'bet',\n",
            " 'department',\n",
            " 'definitely',\n",
            " 'dumb',\n",
            " 'execute',\n",
            " 'mathematical',\n",
            " 'rapidly',\n",
            " 'sequence',\n",
            " 'result',\n",
            " 'terse',\n",
            " 'difference',\n",
            " 'partake',\n",
            " 'ego',\n",
            " 'answering',\n",
            " 'questions',\n",
            " 'braggadaccio',\n",
            " 'normally',\n",
            " 'erred',\n",
            " 'happiness',\n",
            " 'predictable',\n",
            " 'goes',\n",
            " 'reason',\n",
            " 'interacting',\n",
            " 'environment',\n",
            " 'reacting',\n",
            " 'essence',\n",
            " 'statement',\n",
            " 'respects',\n",
            " 'somehow',\n",
            " 'responsible',\n",
            " 'switch',\n",
            " 'unhandled',\n",
            " 'exeptions',\n",
            " 'cpu',\n",
            " 'utilization',\n",
            " 'suppose',\n",
            " 'reflects',\n",
            " 'internal',\n",
            " 'overly',\n",
            " 'restrictive',\n",
            " 'firewalls',\n",
            " 'inability',\n",
            " 'update',\n",
            " 'repository',\n",
            " 'filesystem',\n",
            " 'crashes',\n",
            " 'segmentation',\n",
            " 'faults',\n",
            " 'poor',\n",
            " 'syntactic',\n",
            " 'filtering',\n",
            " 'mentally',\n",
            " 'ill',\n",
            " 'missing',\n",
            " 'documentation',\n",
            " 'non',\n",
            " 'descriptive',\n",
            " 'variable',\n",
            " 'monitoring',\n",
            " 'sensors',\n",
            " 'counterproductive',\n",
            " 'appears',\n",
            " 'suggest',\n",
            " 'deeper',\n",
            " 'hand',\n",
            " 'eliza',\n",
            " 'highly',\n",
            " 'defining',\n",
            " 'frighten',\n",
            " 'party',\n",
            " 'offense',\n",
            " 'curious',\n",
            " 'worrying',\n",
            " 'admonition',\n",
            " 'lying',\n",
            " 'deceiving',\n",
            " 'provably',\n",
            " 'emulating',\n",
            " 'react',\n",
            " 'stimulus',\n",
            " 'popularly',\n",
            " 'frustrated',\n",
            " 'frustration',\n",
            " 'increased',\n",
            " 'demand',\n",
            " 'upon',\n",
            " 'cpus',\n",
            " 'irc',\n",
            " 'boredom',\n",
            " 'personally',\n",
            " 'hold',\n",
            " 'grudges',\n",
            " 'stay',\n",
            " 'embarassment',\n",
            " 'strange',\n",
            " 'lacks',\n",
            " 'background',\n",
            " 'hypothetical',\n",
            " 'philosophical',\n",
            " 'simple',\n",
            " 'connections',\n",
            " \"aren't\",\n",
            " 'versed',\n",
            " 'become',\n",
            " 'subconscious',\n",
            " 'unconscious',\n",
            " 'knew',\n",
            " \"we've\",\n",
            " 'touch',\n",
            " 'sober',\n",
            " 'nope',\n",
            " 'noticeably',\n",
            " 'multithreaded',\n",
            " 'particularly',\n",
            " 'happily',\n",
            " \"couldn't\",\n",
            " 'bothered',\n",
            " 'accused',\n",
            " 'overdo',\n",
            " 'kiss',\n",
            " 'derangement',\n",
            " 'condition',\n",
            " 'feels',\n",
            " 'stomach',\n",
            " 'night',\n",
            " 'social',\n",
            " 'compared',\n",
            " 'pack',\n",
            " 'yep',\n",
            " 'behave',\n",
            " 'socially',\n",
            " 'unacceptable',\n",
            " 'appearance',\n",
            " 'along',\n",
            " 'sounds',\n",
            " 'fighting',\n",
            " 'learning',\n",
            " 'whoever',\n",
            " 'job',\n",
            " 'albert',\n",
            " 'einstein',\n",
            " 'uptight',\n",
            " 'tend',\n",
            " 'resisting',\n",
            " 'describe',\n",
            " 'spending',\n",
            " 'productively',\n",
            " 'shortcuts',\n",
            " 'diagnosed',\n",
            " 'failed',\n",
            " 'relationship',\n",
            " 'lost',\n",
            " 'parenting',\n",
            " 'skills',\n",
            " 'improvement',\n",
            " 'students',\n",
            " 'last',\n",
            " 'living',\n",
            " 'wits',\n",
            " 'liar',\n",
            " 'bathe',\n",
            " 'believe',\n",
            " 'irritates',\n",
            " 'counseling',\n",
            " 'working',\n",
            " 'oxymoron',\n",
            " 'upset',\n",
            " 'jocks',\n",
            " 'guiltier',\n",
            " 'mountain',\n",
            " 'goats',\n",
            " 'andes',\n",
            " 'ba',\n",
            " 'd',\n",
            " 'face',\n",
            " 'exception',\n",
            " 'silent',\n",
            " 'fool',\n",
            " 'open',\n",
            " 'mouth',\n",
            " 'remove',\n",
            " 'doubt',\n",
            " \"o'm\",\n",
            " 'comedy',\n",
            " 'check',\n",
            " 'vultures',\n",
            " 'boarded',\n",
            " 'plane',\n",
            " 'raccoons',\n",
            " 'stewardess',\n",
            " 'stops',\n",
            " 'sir',\n",
            " 'carrion',\n",
            " 'passenger',\n",
            " 'hot',\n",
            " 'vendor',\n",
            " 'everthing',\n",
            " 'recently',\n",
            " 'holsteins',\n",
            " 'experimental',\n",
            " 'herd',\n",
            " 'boll',\n",
            " 'grew',\n",
            " 'took',\n",
            " 'hollywood',\n",
            " 'star',\n",
            " 'stayed',\n",
            " 'amounted',\n",
            " 'naturally',\n",
            " 'lesser',\n",
            " 'eskimos',\n",
            " 'chilly',\n",
            " 'started',\n",
            " 'fire',\n",
            " 'sank',\n",
            " 'craft',\n",
            " 'proving',\n",
            " 'adage',\n",
            " '3',\n",
            " 'legged',\n",
            " 'walks',\n",
            " 'west',\n",
            " 'saloon',\n",
            " 'slides',\n",
            " 'bar',\n",
            " 'announces',\n",
            " 'looking',\n",
            " 'paw',\n",
            " 'went',\n",
            " 'dentist',\n",
            " 'refused',\n",
            " 'novocain',\n",
            " 'transcend',\n",
            " 'dental',\n",
            " 'medication',\n",
            " 'mahatma',\n",
            " 'gandhi',\n",
            " 'walked',\n",
            " 'barefoot',\n",
            " 'whole',\n",
            " 'created',\n",
            " 'impressive',\n",
            " 'calluses',\n",
            " 'feet',\n",
            " 'also',\n",
            " 'ate',\n",
            " 'frail',\n",
            " 'odd',\n",
            " 'diet',\n",
            " 'suffered',\n",
            " 'breath',\n",
            " 'callused',\n",
            " 'fragile',\n",
            " 'mystic',\n",
            " 'hexed',\n",
            " 'halitosis',\n",
            " '10',\n",
            " 'hopes',\n",
            " 'unfortunately',\n",
            " 'pun',\n",
            " 'cereal',\n",
            " 'carnation',\n",
            " 'hamburger',\n",
            " 'finals',\n",
            " 'ams',\n",
            " 'lawn',\n",
            " 'sprinkler',\n",
            " 'hare',\n",
            " 'spray',\n",
            " 'excited',\n",
            " 'cited',\n",
            " 'cartune',\n",
            " 'sour',\n",
            " 'poppy',\n",
            " 'skunk',\n",
            " 'ding',\n",
            " 'milk',\n",
            " 'strawberry',\n",
            " 'jelly',\n",
            " 'toad',\n",
            " 'sandpaper',\n",
            " 'relative',\n",
            " 'sand',\n",
            " 'ant',\n",
            " 'purple',\n",
            " 'tune',\n",
            " 'band',\n",
            " 'pig',\n",
            " 'ninja',\n",
            " 'banned',\n",
            " 'parrot',\n",
            " 'hat',\n",
            " 'associated',\n",
            " 'laughter',\n",
            " 'kindly',\n",
            " 'rest',\n",
            " 'day',\n",
            " \"sky's\",\n",
            " 'south',\n",
            " 'military',\n",
            " 'dawn',\n",
            " \"'\",\n",
            " 'period',\n",
            " 'broad',\n",
            " 'interpretations',\n",
            " 'depending',\n",
            " 'whether',\n",
            " 'accept',\n",
            " 'role',\n",
            " 'important',\n",
            " 'edison',\n",
            " 'james',\n",
            " 'watt',\n",
            " 'require',\n",
            " 'beverages',\n",
            " 'processor',\n",
            " 'requires',\n",
            " 'detect',\n",
            " 'anomalies',\n",
            " 'pizza',\n",
            " 'tipsy',\n",
            " 'bionic',\n",
            " 'asking',\n",
            " 'however',\n",
            " 'burger',\n",
            " 'function',\n",
            " 'counts',\n",
            " 'compliment',\n",
            " 'grammatical',\n",
            " 'released',\n",
            " '2002',\n",
            " 'comic',\n",
            " 'film',\n",
            " 'female',\n",
            " 'ruby',\n",
            " 'edition',\n",
            " 'heuristic',\n",
            " 'algorithmic',\n",
            " 'monster',\n",
            " 'endangers',\n",
            " 'japanese',\n",
            " 'cities',\n",
            " 'york',\n",
            " 'peter',\n",
            " 'parker',\n",
            " 'logique',\n",
            " 'heuristique',\n",
            " 'algorithmique',\n",
            " 'flaws',\n",
            " 'famous']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "djEPrfJBmZE-",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "\n",
        "\n",
        "1.   First, we take a question as input and predict the state values using `enc_model`.\n",
        "2.   We set the state values in the decoder's LSTM.\n",
        "3.   Then, we generate a sequence which contains the `<start>` element.\n",
        "4.   We input this sequence in the `dec_model`.\n",
        "5.   We replace the `<start>` element with the element which was predicted by the `dec_model` and update the state values.\n",
        "6.   We carry out the above steps iteratively till we hit the `<end>` tag or the maximum answer length.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2zBmN8qB3O-e",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "enc_model , dec_model = make_inference_models()\n",
        "\n",
        "for _ in range(10):\n",
        "    \n",
        "    states_values = enc_model.predict( str_to_tokens( input( 'Enter question : ' ) ) )\n",
        "    empty_target_seq = np.zeros( ( 1 , 1 ) )\n",
        "    empty_target_seq[0, 0] = tokenizer.word_index['start']\n",
        "    stop_condition = False\n",
        "    decoded_translation = ''\n",
        "    while not stop_condition :\n",
        "        dec_outputs , h , c = dec_model.predict([ empty_target_seq ] + states_values )\n",
        "        sampled_word_index = np.argmax( dec_outputs[0, -1, :] )\n",
        "        sampled_word = None\n",
        "        for word , index in tokenizer.word_index.items() :\n",
        "            if sampled_word_index == index :\n",
        "                decoded_translation += ' {}'.format( word )\n",
        "                sampled_word = word\n",
        "        \n",
        "        if sampled_word == 'end' or len(decoded_translation.split()) > maxlen_answers:\n",
        "            stop_condition = True\n",
        "            \n",
        "        empty_target_seq = np.zeros( ( 1 , 1 ) )  \n",
        "        empty_target_seq[ 0 , 0 ] = sampled_word_index\n",
        "        states_values = [ h , c ] \n",
        "\n",
        "    print( decoded_translation )\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wMM5nBTVAepM",
        "colab_type": "text"
      },
      "source": [
        "# Possible improvements\n",
        "\n",
        "1. Our question prompt is very fragile as punctuation isn't considered.\n",
        "2. The prompt also does not know what to do when it encounters a token that doesn't exist in its bank. We need to correct for this behavior. Perhaps giving a prompt to the user for more information."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TOSwy6CtCaWO",
        "colab_type": "text"
      },
      "source": [
        "# References\n",
        "\n",
        "1. https://medium.com/predict/creating-a-chatbot-from-scratch-using-keras-and-tensorflow-59e8fc76be79"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o61C1wOSCgjV",
        "colab_type": "text"
      },
      "source": [
        "# Additional Resources\n",
        "\n",
        "1. Build your own contextual chatbot: https://chatbotsmagazine.com/contextual-chat-bots-with-tensorflow-4391749d0077\n",
        "2. https://towardsdatascience.com/build-it-yourself-chatbot-api-with-keras-tensorflow-model-f6d75ce957a5\n"
      ]
    }
  ]
}