{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Ex3_neural_network_control.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IHux9hQYYfle",
        "colab_type": "text"
      },
      "source": [
        "# Deep model predictive control\n",
        " This code was borrowed from a the following class project. \n",
        "\n",
        "\n",
        "\n",
        "\n",
        "[Link to the github repo](https://github.com/mdhoffschmidt/deepmpc)\n",
        "\n",
        "[Link to the lecture notes that were followed (Berkeley)](http://rll.berkeley.edu/deeprlcourse/f17docs/lecture_9_model_based_rl.pdf) (very good)\n",
        "\n",
        "[Link to the original DeepMPC website and papers](http://deepmpc.cs.cornell.edu/)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lv3NOnt8OIaB",
        "colab_type": "code",
        "outputId": "c74d27d5-3fb6-4009-e31d-64fee2ec0e83",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "!git clone https://github.com/mdhoffschmidt/deepmpc\n",
        "  "
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "fatal: destination path 'deepmpc' already exists and is not an empty directory.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HWnDha33OTRs",
        "colab_type": "code",
        "outputId": "6380378f-cbce-4ead-d707-dd3565c020c8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "cd deepmpc"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/deepmpc\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NyEIE8xtOY2r",
        "colab_type": "code",
        "outputId": "23fbdc7f-3534-4a00-ca82-260fe5f481b2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        }
      },
      "source": [
        "!pip install tensorboardX\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: tensorboardX in /usr/local/lib/python3.6/dist-packages (1.8)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from tensorboardX) (1.12.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from tensorboardX) (1.16.4)\n",
            "Requirement already satisfied: protobuf>=3.2.0 in /usr/local/lib/python3.6/dist-packages (from tensorboardX) (3.7.1)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from protobuf>=3.2.0->tensorboardX) (41.0.1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H8FBLQOmTzUS",
        "colab_type": "code",
        "outputId": "b1dd203c-fe78-4c77-c1a6-93185aa4c178",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "# need to downgrade piglet to view the environment\n",
        "!pip install pyglet==1.3.2"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: pyglet==1.3.2 in /usr/local/lib/python3.6/dist-packages (1.3.2)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from pyglet==1.3.2) (0.16.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TV3OPhyfQx51",
        "colab_type": "code",
        "outputId": "d5660085-760e-4372-8044-186c9afe2089",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 407
        }
      },
      "source": [
        "!apt-get install -y xvfb python-opengl\n",
        "!pip install gym pyvirtualdisplay"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "python-opengl is already the newest version (3.1.0+dfsg-1).\n",
            "xvfb is already the newest version (2:1.19.6-1ubuntu4.3).\n",
            "The following package was automatically installed and is no longer required:\n",
            "  libnvidia-common-410\n",
            "Use 'apt autoremove' to remove it.\n",
            "0 upgraded, 0 newly installed, 0 to remove and 4 not upgraded.\n",
            "Requirement already satisfied: gym in /usr/local/lib/python3.6/dist-packages (0.10.11)\n",
            "Requirement already satisfied: pyvirtualdisplay in /usr/local/lib/python3.6/dist-packages (0.2.4)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from gym) (1.12.0)\n",
            "Requirement already satisfied: pyglet>=1.2.0 in /usr/local/lib/python3.6/dist-packages (from gym) (1.3.2)\n",
            "Requirement already satisfied: requests>=2.0 in /usr/local/lib/python3.6/dist-packages (from gym) (2.21.0)\n",
            "Requirement already satisfied: numpy>=1.10.4 in /usr/local/lib/python3.6/dist-packages (from gym) (1.16.4)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.6/dist-packages (from gym) (1.3.1)\n",
            "Requirement already satisfied: EasyProcess in /usr/local/lib/python3.6/dist-packages (from pyvirtualdisplay) (0.2.7)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from pyglet>=1.2.0->gym) (0.16.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests>=2.0->gym) (2019.6.16)\n",
            "Requirement already satisfied: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests>=2.0->gym) (2.8)\n",
            "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests>=2.0->gym) (3.0.4)\n",
            "Requirement already satisfied: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests>=2.0->gym) (1.24.3)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u70acg5wXJvn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import random\n",
        "from collections import namedtuple\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Import built-in packages.\n",
        "import time\n",
        "import math\n",
        "\n",
        "# Import third-party packages.\n",
        "import gym\n",
        "import matplotlib.pyplot as plt\n",
        "from tensorboardX import SummaryWriter\n",
        "import torch\n",
        "import cvxpy as cp\n",
        "import numpy as np\n",
        "from IPython import display as ipythondisplay\n",
        "from pyvirtualdisplay import Display"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PnxjOIGrXXtf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "class Agent:\n",
        "\t\"\"\"Agent trainer.\n",
        "\t\"\"\"\n",
        "\n",
        "\tBATCH_SIZE = 32\n",
        "\tMIN_SAMPLE = 64\n",
        "\tLR = 0.00025\n",
        "\tL2 = 0.0030\n",
        "\n",
        "\tdef __init__(self, model, memory):\n",
        "\t\t\"\"\"Special method for object initialisation.\n",
        "\t\t:param model: the predictive model.\n",
        "\t\t:type model: torch module.\n",
        "\t\t:param memory: replay memory buffer object.\n",
        "\t\t:type memory: buffer.\n",
        "\t\t\"\"\"\n",
        "\n",
        "\t\t# Set the model and it loss.\n",
        "\t\tself.model = model\n",
        "\t\tself.model_loss = torch.nn.MSELoss()\n",
        "\t\tself.model_optimizer = torch.optim.RMSprop(self.model.parameters(), lr=self.LR, weight_decay=self.L2)\n",
        "\n",
        "\t\t# Set the memroy.\n",
        "\t\tself.memory = memory\n",
        "\n",
        "\t\t# Set the performance.\n",
        "\t\tself.perf = 0.0\n",
        "\t\tself.dperf = 0.0\n",
        "\n",
        "\t\treturn\n",
        "\n",
        "\tdef load(self, path=\"agent\", model=\"model\"):\n",
        "\t\t\"\"\"Load the model of the agent.\n",
        "\t\t:param path: the name of the path.\n",
        "\t\t:type path: str.\n",
        "\t\t:param model: the name of the model.\n",
        "\t\t:type model: str.\n",
        "\t\t\"\"\"\n",
        "\t\tfilename = \"{}/{}.txt\".format(path, model)\n",
        "\t\tself.model.load_state_dict(torch.load(filename))\n",
        "\t\treturn\n",
        "\n",
        "\tdef save(self, path=\"agent\", model=\"model\"):\n",
        "\t\t\"\"\"Save the policy and target networks.\n",
        "\t\t:param path: the name of the path.\n",
        "\t\t:type path: str.\n",
        "\t\t:param model: the name of the model.\n",
        "\t\t:type model: str.\t\t\n",
        "\t\t\"\"\"\n",
        "\t\tfilename = \"{}/{}.txt\".format(path, model)\n",
        "\t\ttorch.save(self.model.state_dict(), filename)\n",
        "\t\treturn\n",
        "\n",
        "\t# ------------------------- #\n",
        "\t# ---  0. Model methods --- #\n",
        "\t# ------------------------- #\n",
        "\n",
        "\tdef model_parameter_norm(self):\n",
        "\t\t\"\"\"Returns the norm of the model parameters.\n",
        "\t\t:return: the norm of the parameters.\n",
        "\t\t:rtype: float.\n",
        "\t\t\"\"\"\n",
        "\t\tnorm = torch.tensor(0.0)\n",
        "\t\tfor param in self.model.parameters():\n",
        "\t\t\tnorm += torch.norm(param)\n",
        "\t\treturn norm.item()\n",
        "\n",
        "\tdef model_performance(self):\n",
        "\t\t\"\"\"Evaluate the performance of the model on the memory.\n",
        "\t\t:return: the performance for the model.\n",
        "\t\t:rtype: float.\n",
        "\t\t\"\"\"\n",
        "\n",
        "\t\t# Set the model in evaluation mode.\n",
        "\t\tself.model.eval()\n",
        "\n",
        "\t\t# Get the batch.\n",
        "\t\tbatch = self.memory.batch()\n",
        "\t\tstate, action, next_state = batch\n",
        "\n",
        "\t\t# Get the next state predictions.\n",
        "\t\tpred_state = self.model(state, action)\n",
        "\n",
        "\t\t# Get the performance. \n",
        "\t\terror = ( pred_state - next_state )\n",
        "\t\tperf = torch.mean( error * error )\n",
        "\n",
        "\t\treturn perf.item()\n",
        "\n",
        "\tdef optimize(self):\n",
        "\t\t\"\"\"Samples a random batch from replay memory and optimize.\n",
        "\t\t:return: the loss.\n",
        "\t\t:rtype: float.\t\t\n",
        "\t\t\"\"\"\n",
        "\n",
        "\t\t# Set the model in training mode.\n",
        "\t\tself.model.train()\n",
        "\n",
        "\t\t# Check the size of the memory.\n",
        "\t\tif len(self.memory) <= self.MIN_SAMPLE:\n",
        "\t\t\treturn None\n",
        "\n",
        "\t\t# Get samples out of the memory.\n",
        "\t\tbatch = self.memory.sample(self.BATCH_SIZE)\n",
        "\t\tstate, action, next_state = batch\n",
        "\n",
        "\t\t# Get the predictions for the next states.\n",
        "\t\tpred_state = self.model(state, action)\n",
        "\n",
        "\t\t# Set the gradients of the optimizer.\n",
        "\t\tself.model_optimizer.zero_grad()\n",
        "\n",
        "\t\t# Perform the backward step.\n",
        "\t\tloss = self.model_loss(pred_state, next_state)\n",
        "\t\tloss.backward()\n",
        "\n",
        "\t\t# Perform one optimisation step.\n",
        "\t\tself.model_optimizer.step()\n",
        "\n",
        "\t\treturn loss.item()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bv_bmBsfXh9J",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "class Memory(object):\n",
        "\t\"\"\"Class that handles a replay memory.\n",
        "\t:attr capacity: the memory capacity.\n",
        "\t:type capacity: int.\n",
        "\t:attr memory: the samples memory.\n",
        "\t:type memory: list.\n",
        "\t:attr position: the memory position.\n",
        "\t:type position: int.\n",
        "\t\"\"\"\n",
        "\n",
        "\tTransition = namedtuple('Transition', \n",
        "\t\t('state', 'action', 'next_state', 'reward'))\t\n",
        "\n",
        "\tdef __init__(self, capacity):\n",
        "\t\t\"\"\"Special method for class object construction.\n",
        "\t\t\"\"\"\n",
        "\t\tself.capacity = capacity\n",
        "\t\tself.memory = []\n",
        "\t\tself.position = 0\n",
        "\t\treturn\n",
        "\n",
        "\tdef __repr__(self):\n",
        "\t\t\"\"\"Special method for class object representation.\n",
        "\t\t\"\"\"\n",
        "\t\t_repr = {\"name\":self.__class__.__name__}\n",
        "\t\t_repr.update({\"capacity\":self.capacity})\n",
        "\t\t_repr.update({\"position\":self.position})\n",
        "\t\treturn _repr\n",
        "\n",
        "\tdef __str__(self):\n",
        "\t\t\"\"\"Special methof for class object representation.\n",
        "\t\t\"\"\"\n",
        "\t\tmsg = [\"{}: {}\".format(a, b) for a, b in self.__repr__().items()]\n",
        "\t\treturn \"\\n\".join(msg)\n",
        "\n",
        "\tdef __len__(self):\n",
        "\t\t\"\"\"Special method for class object length.\n",
        "\t\t\"\"\"\n",
        "\t\treturn len(self.memory)\n",
        "\n",
        "\tdef push(self, *transition):\n",
        "\t\t\"\"\"Save a transition.\n",
        "\t\t:param transition: the state, reward, action transition to store.\n",
        "\t\t:type transition: list of torch tensors.\n",
        "\t\t\"\"\"\n",
        "\n",
        "\t\t# Check the size of the memory.\n",
        "\t\tif len(self.memory) < self.capacity:\n",
        "\t\t\tself.memory.append(None)\n",
        "\n",
        "\t\t# Update the memory with the transition.\n",
        "\t\tself.memory[self.position] = self.Transition(*transition)\n",
        "\n",
        "\t\t# Update the current pisition.\n",
        "\t\tself.position = (self.position + 1) % self.capacity\n",
        "\n",
        "\t\treturn\n",
        "\n",
        "\tdef batch(self):\n",
        "\t\t\"\"\"Returns the memory batch.\n",
        "\t\t\"\"\"\n",
        "\n",
        "\t\t# Handle the transition.\n",
        "\t\tbatch = self.Transition(*zip(*self.memory))\n",
        "\n",
        "\t\t# Handle transition size.\n",
        "\t\tstate = torch.cat(batch.state, dim=1)\n",
        "\t\taction = torch.cat(batch.action, dim=1)\n",
        "\t\tnext_state = torch.cat(batch.next_state, dim=1)\n",
        "\n",
        "\t\treturn state, action, next_state\n",
        "\n",
        "\tdef sample(self, batch_size):\n",
        "\t\t\"\"\"Random samples from the memory.\n",
        "\t\t:param batch_size: the size of the batch.\n",
        "\t\t:type batch_size: int.\n",
        "\t\t\"\"\"\n",
        "\n",
        "\t\t# Check the size of the memeory.\n",
        "\t\tif self.__len__() < batch_size:\n",
        "\t\t\tbatch_size = self.__len__()\n",
        "\n",
        "\t\t# Sample random transitions fro the memory.\n",
        "\t\ttransitions = random.sample(self.memory, batch_size)\n",
        "\n",
        "\t\t# Handle the transitions.\n",
        "\t\tbatch = self.Transition(*zip(*transitions))\n",
        "\n",
        "\t\t# Handle transition size.\n",
        "\t\tstate = torch.cat(batch.state, dim=1)\n",
        "\t\taction = torch.cat(batch.action, dim=1)\n",
        "\t\tnext_state = torch.cat(batch.next_state, dim=1)\n",
        "\n",
        "\t\treturn state, action, next_state"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1xujn5VDXnJz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "class Predictor(nn.Module):\n",
        "\t\"\"\"Predictor network\n",
        "\t\"\"\"\n",
        "\n",
        "\tdef __init__(self, state_dim, action_dim, hidden=64):\n",
        "\t\t\"\"\"Special method for class initialisation.\n",
        "\t\t:param state_dim: Dimension of input state.\n",
        "\t\t:type state_dim: int.\n",
        "\t\t:param action_dim: Dimension of input action.\n",
        "\t\t:type action_dim: int.\n",
        "\t\t\"\"\"\n",
        "\t\tsuper(Predictor, self).__init__()\n",
        "\n",
        "\t\tself.s_dim = state_dim\n",
        "\t\tself.a_dim = action_dim\n",
        "\t\tself.hidden = hidden\n",
        "\t\n",
        "\t\tself.fcs1 = nn.Linear(self.s_dim, self.hidden)\n",
        "\t\tself.fca1 = nn.Linear(self.a_dim, self.hidden)\n",
        "\n",
        "\t\tself.fc1 = nn.Linear(2*self.hidden, self.hidden)\n",
        "\t\tself.fc2 = nn.Linear(self.hidden, self.s_dim)\n",
        "\t\t\n",
        "\t\treturn\n",
        "\n",
        "\tdef forward(self, s, a):\n",
        "\t\t\"\"\"Returns Value function Q(s,a) obtained from critic network.\n",
        "\t\t:param s: state with size (s_dim, n).\n",
        "\t\t:type s: torch tensor or numpy array.\n",
        "\t\t:param a: action with size (a_dim, n)\n",
        "\t\t:type a: Torch tensor or numpy array.\n",
        "\t\t\"\"\"\n",
        "\n",
        "\t\t# Check numpy type for a and a.\n",
        "\t\tFLAG = False\n",
        "\t\tif isinstance(s, np.ndarray):\n",
        "\t\t\ts = torch.Tensor(s)\n",
        "\t\t\tFLAG = True\n",
        "\t\tif isinstance(a, np.ndarray):\n",
        "\t\t\ta = torch.Tensor(a)\n",
        "\t\t\tFLAG = True\n",
        "\n",
        "\t\t# Check torch type of s and a.\n",
        "\t\tif not isinstance(s, torch.Tensor):\n",
        "\t\t\traise TypeError()\n",
        "\t\tif not isinstance(a, torch.Tensor):\n",
        "\t\t\traise TypeError()\n",
        "\n",
        "\t\t# Tranpose the state and action.\n",
        "\t\ts = s.t()\n",
        "\t\ta = a.t()\n",
        "\n",
        "\t\t# Perform the forward pass.\n",
        "\t\ts1 = F.relu(self.fcs1(s))\n",
        "\t\ta1 = F.relu(self.fca1(a))\n",
        "\t\ts2 = torch.cat((s1, a1), dim=1)\n",
        "\t\t\n",
        "\t\t# Compute the output.\n",
        "\t\ts3 = F.relu(self.fc1(s2))\n",
        "\t\tout = self.fc2(s3).t()\n",
        "\n",
        "\t\t# Check if input was numpy.\n",
        "\t\tif FLAG is True:\n",
        "\t\t\tout = out.detach().numpy()\n",
        "\n",
        "\t\treturn out\n",
        "\n",
        "\tdef state_matrix(self, s, a):\n",
        "\t\t\"\"\"Returns the state matrix.\n",
        "\t\t:param s: state with size (s_dim, 1).\n",
        "\t\t:type s: numpy array.\n",
        "\t\t:param a: action with size (a_dim, 1)\n",
        "\t\t:type a: numpy array.\t\t\n",
        "\t\t\"\"\"\n",
        "\t\ts = torch.autograd.Variable(torch.Tensor(s), requires_grad=True)\n",
        "\t\ta = torch.autograd.Variable(torch.Tensor(a), requires_grad=True)\t\t\n",
        "\t\tout = self.__call__(s, a)\n",
        "\t\tA = []\n",
        "\t\tfor i in range(self.s_dim):\n",
        "\t\t\tout[i].backward(retain_graph=True)\n",
        "\t\t\tgrad = s.grad.detach().numpy().copy()\n",
        "\t\t\tA.append(grad)\n",
        "\t\t\ta.grad.zero_()\n",
        "\t\t\ts.grad.zero_()\n",
        "\t\treturn np.transpose(np.hstack(A))\n",
        "\n",
        "\tdef state_matrix_diff(self, s, a, eps=1.0E-3):\n",
        "\t\t\"\"\"Returns the state matrix.\n",
        "\t\t:param s: state with size (s_dim, 1).\n",
        "\t\t:type s: numpy array.\n",
        "\t\t:param a: action with size (a_dim, 1)\n",
        "\t\t:type a: numpy array.\n",
        "\t\t\"\"\"\n",
        "\n",
        "\t\t# Set the disturbation matrix.\n",
        "\t\td = eps * np.identity(self.s_dim)\n",
        "\n",
        "\t\t# Repeat the state and action vectors.\n",
        "\t\ts = np.tile(s, (1, self.s_dim))\n",
        "\t\ta = np.tile(a, (1, self.s_dim))\n",
        "\n",
        "\t\t# Build the state difference matrix.\n",
        "\t\tA = ( self.forward(s + d, a) - self.forward(s - d, a) ) / ( 2 * eps )\n",
        "\n",
        "\t\treturn A\n",
        "\n",
        "\tdef input_matrix(self, s, a):\n",
        "\t\t\"\"\"Returns the input matrix.\n",
        "\t\t:param s: state with size (s_dim, 1).\n",
        "\t\t:type s: numpy array.\n",
        "\t\t:param a: action with size (a_dim, 1)\n",
        "\t\t:type a: numpy array.\t\t\n",
        "\t\t\"\"\"\n",
        "\t\ts = torch.autograd.Variable(torch.Tensor(s), requires_grad=True)\n",
        "\t\ta = torch.autograd.Variable(torch.Tensor(a), requires_grad=True)\t\t\n",
        "\t\tout = self.__call__(s, a)\n",
        "\t\tB = []\n",
        "\t\tfor i in range(self.s_dim):\n",
        "\t\t\tout[i].backward(retain_graph=True)\n",
        "\t\t\tgrad = a.grad.detach().numpy().copy()\n",
        "\t\t\tB.append(grad)\n",
        "\t\t\ta.grad.zero_()\n",
        "\t\t\ts.grad.zero_()\n",
        "\t\treturn np.transpose(np.hstack(B))\n",
        "\n",
        "\tdef input_matrix_diff(self, s, a, eps=1.0E-3):\n",
        "\t\t\"\"\"Returns the input matrix.\n",
        "\t\t:param s: state with size (s_dim, 1).\n",
        "\t\t:type s: numpy array.\n",
        "\t\t:param a: action with size (a_dim, 1)\n",
        "\t\t:type a: numpy array.\n",
        "\t\t\"\"\"\n",
        "\n",
        "\t\t# Set the disturbation matrix.\n",
        "\t\td = eps * np.identity(self.a_dim)\n",
        "\n",
        "\t\t# Repeat the state and action vectors.\n",
        "\t\ts = np.tile(s, (1, self.a_dim))\n",
        "\t\ta = np.tile(a, (1, self.a_dim))\n",
        "\n",
        "\t\t# Build the state difference matrix.\n",
        "\t\tB = ( self.forward(s, a + d) - self.forward(s, a - d) ) / ( 2 * eps )\n",
        "\n",
        "\t\treturn B\n",
        "\n",
        "\tdef linearise(self, s, a, diff=False):\n",
        "\t\t\"\"\"Linearise the model around s, a.\n",
        "\t\t:param s: state with size (s_dim, 1).\n",
        "\t\t:type s: numpy array.\n",
        "\t\t:param a: action with size (a_dim, 1)\n",
        "\t\t:type a: numpy array.\n",
        "\t\t:param diff: Use finite difference if True, False othewise.\n",
        "\t\t:type diff: bool.\t\n",
        "\t\t\"\"\"\n",
        "\t\tif diff:\n",
        "\t\t\tA = self.state_matrix_diff(s, a)\n",
        "\t\t\tB = self.input_matrix_diff(s, a)\n",
        "\t\telse:\n",
        "\t\t\tA = self.state_matrix(s, a)\n",
        "\t\t\tB = self.input_matrix(s, a)\n",
        "\t\treturn (A, B)\n",
        "\n",
        "\tdef pred_linear(self, x, u, s, a):\n",
        "\t\treturn"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Yh3IX_E5aaaz",
        "colab_type": "code",
        "outputId": "945606d7-6cf4-4944-d614-21d5299a8768",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 268
        }
      },
      "source": [
        "# prepare to animate\n",
        "from matplotlib import animation\n",
        "from IPython.display import HTML\n",
        "\n",
        "# First we create the empty figure which we want to animate\n",
        "fig, ax = plt.subplots()\n",
        "\n",
        "ax.set_xlim(( 0, 500))\n",
        "ax.set_ylim((0, 500))\n",
        "\n",
        "frame = ax.imshow(np.asarray(255*np.ones((500,500,3)),dtype=np.uint8))\n",
        "\n",
        "def init():\n",
        "    frame.set_data(np.asarray(255*np.ones((500,500,3)),dtype=np.uint8))\n",
        "    return (frame,)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAQsAAAD8CAYAAABgtYFHAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nSOryX7Ryu4GxPG+mAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fmeccRzIPWnj",
        "colab_type": "code",
        "outputId": "889cbfdd-cbe4-4826-9bfc-628829ea45c9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "\n",
        "# get the display started to view the gym in colab\n",
        "#display = Display(visible=0, size=(400, 300))\n",
        "#display.start()\n",
        "#screens=np.ones((500,500,3,20),dtype=np.uint8)\n",
        "\n",
        "\n",
        "# Set hyper parameters.\n",
        "EPISODE = 200\n",
        "MAX_COUNTER = 200\n",
        "CAPACITY = 100000\n",
        "LEVEL = -1\n",
        "MODEL = \"model\"\n",
        "AGENT = \"agent\"\n",
        "\n",
        "# Set the controller variables.\n",
        "T = 50\n",
        "n = 3\n",
        "m = 1\n",
        "x = cp.Variable((n, T+1))\n",
        "u = cp.Variable((m, T))\n",
        "\n",
        "s0 = np.asarray([[1.0], [0.0], [0.0]])\n",
        "a0 = np.asarray([[0.0]])\n",
        "beta = np.asarray([1.0, 1.0, 0.1])\n",
        "\n",
        "A = cp.Parameter((n, n))\n",
        "B = cp.Parameter((n, m))\n",
        "x0 = cp.Parameter((n))\n",
        "u0 = cp.Parameter((m))\n",
        "\n",
        "# Loop on the horizon.\n",
        "cost = 0\n",
        "constr = []\n",
        "\n",
        "for t in range(T):\n",
        "\n",
        "\t# Add the cost.\n",
        "\tcost += cp.sum_squares( (x[:,t+1] + x0 - s0[:,0]) * beta ) + cp.sum_squares( 0.001 * u[:,t])\n",
        "\n",
        "\t# Set the constraint.\n",
        "\tconstr += [x[:,t+1] == A * x[:,t] + B[:,0] * u[:,t],\n",
        "\tcp.norm(u[:,t] + u0, \"inf\") <= 2.0]\n",
        "\n",
        "# Set the initial constraint.\n",
        "constr += [ x[:,0] == 0]\n",
        "\n",
        "# Build the problem.\n",
        "problem = cp.Problem(cp.Minimize(cost), constr)\n",
        "\n",
        "# -------------------------------------------- #\n",
        "\n",
        "def controller(x1=None, u1=None, A=None, B=None, new=True):\n",
        "\t\"\"\"\n",
        "\t\"\"\"\n",
        "\n",
        "\t# Solve the problem.\n",
        "\tproblem.solve(warm_start=True)\n",
        "\n",
        "\treturn u[:,0].value.reshape(-1,1) #+ u0.reshape(-1,1)\n",
        "\n",
        "# -------------------------------------------- #\n",
        "\n",
        "\n",
        "# Make the gym environment.\n",
        "env = gym.make(\"Pendulum-v0\")\n",
        "\n",
        "# Get the environment action space.\n",
        "action_space = env.action_space.shape[0]\n",
        "state_space = env.observation_space.shape[0]\n",
        "\n",
        "# Get the memory.\n",
        "memory = Memory(CAPACITY)\n",
        "\n",
        "# Get the predictor.\n",
        "predictor = Predictor(state_space, action_space, hidden=128)\n",
        "\n",
        "# Load the trainer.\n",
        "agent = Agent(predictor, memory)\n",
        "\n",
        "# Load a pretrained model.\n",
        "try:\n",
        "  agent.load(AGENT, MODEL)\n",
        "except:\n",
        "  print(\"Unable to load the agent.\")\n",
        "\n",
        "# Load the writer.\n",
        "number = int( time.time() % ( 3600 * 24 ))\n",
        "writer = SummaryWriter(\"tensorboard/runs_{}\".format(number))\n",
        "\n",
        "# Set the global counter.\n",
        "global_counter = 0\n",
        "verbose = False\n",
        "\n",
        "# Perform a number of episodes.\n",
        "for i_episode in range(EPISODE):\n",
        "\n",
        "  # Reset the environment.\n",
        "  state = env.reset()\n",
        "  state = state.reshape(-1, 1)\n",
        "\n",
        "  # Set the done flag.\n",
        "  done = False\n",
        "\n",
        "  # Set the initial counter.\n",
        "  counter = 0\n",
        "  action = a0\n",
        "  \n",
        "  # show the environment\n",
        "  #prev_screen = env.render(mode='rgb_array')\n",
        "  #plt.imshow(prev_screen)\n",
        "  \n",
        "  # Step on the environment while not done.\n",
        "  while not done:\n",
        "\n",
        "    # Render the environment.\n",
        "    # env.render()\n",
        "\n",
        "    # Linearise.\n",
        "    A_new, B_new = predictor.linearise(state, action, diff=True)\n",
        "\n",
        "    # Get the controller action.\n",
        "    if i_episode > LEVEL:\n",
        "      control_action = True\n",
        "    else:\n",
        "      control_action = False\n",
        "\n",
        "    # Controller.\n",
        "    if control_action is True:\n",
        "      t_a = time.time()\n",
        "\n",
        "      x0.value = state[:,0]\n",
        "      u0.value = action[:,0]\n",
        "      A.value = A_new\n",
        "      B.value = B_new\n",
        "\n",
        "      #action = controller()\n",
        "\n",
        "      if counter == 0:\n",
        "        problem.solve()\n",
        "      else:\n",
        "        #print(A.value)\n",
        "        #print(B.value)\n",
        "        problem.solve(solver=cp.SCS, warm_start=True)\n",
        "      problem_value_print=\"optimal value with CVXOPT: {}\".format(problem.value)\n",
        "\n",
        "      action = (u[:,0].value + u0.value).reshape(-1, 1)\n",
        "\n",
        "      state_print=\"{}\".format(state)\n",
        "      action_print=\"{}\".format(action)   \n",
        "\n",
        "      t_b = time.time()\n",
        "      time_print=\"Elapsed time = {}\".format(t_b - t_a)\n",
        "    else:\n",
        "      action = env.action_space.sample()\n",
        "      action = action.reshape(-1, 1)\n",
        "\n",
        "    # Step on the environment.\n",
        "    next_state, reward, done, info = env.step(action)\n",
        "    next_state  = next_state.reshape(-1, 1)\n",
        "\n",
        "    # Push the results to the memory.\n",
        "    memory.push(\n",
        "      torch.Tensor(state), \n",
        "      torch.Tensor(action), \n",
        "      torch.Tensor(next_state),\n",
        "      None)\n",
        "\n",
        "    # Update the next state.\n",
        "    state = next_state\n",
        "\n",
        "    # Increment the counter.\n",
        "    counter += 1\n",
        "    global_counter += 1\n",
        "\n",
        "    # Check the counter.\n",
        "    if counter > MAX_COUNTER:\n",
        "      break\n",
        "\n",
        "    # Display.\n",
        "    '''\n",
        "    screens[:,:,:,(counter % 20)-1] = env.render(mode='rgb_array')\n",
        "    if counter % 20 == 0:\n",
        "      def animate(i):\n",
        "        frame.set_data(screens[:,:,:,i])\n",
        "        return (frame,)\n",
        "      anim = animation.FuncAnimation(fig, animate, init_func=init,\n",
        "                               frames=20, interval=20, \n",
        "                               blit=True)\n",
        "      HTML(anim.to_html5_video())\n",
        "      ipythondisplay.clear_output(wait=True)\n",
        "      ipythondisplay.display(plt.gcf())\n",
        "    '''\n",
        "    if counter % 20 == 0:\n",
        "      print(problem_value_print)  \n",
        "      print(state_print)   \n",
        "      print(action_print)\n",
        "      print(time_print)\n",
        "      print(\"counter = {}\".format(counter))\n",
        "\n",
        "    # Train the model.\n",
        "    if len(memory) > agent.BATCH_SIZE:\n",
        "\n",
        "      # Get the old perf.\n",
        "      C_old = agent.model_performance()\n",
        "\n",
        "      # Perform one optimisation step.\n",
        "      loss = agent.optimize()\n",
        "\n",
        "      # Get the new perf.\n",
        "      C_new = agent.model_performance()\n",
        "\n",
        "      # Add the memory performance.\n",
        "      writer.add_scalar(\"C\",\n",
        "        math.log(C_new / (C_old + 1.0e-8)), \n",
        "        global_counter)\n",
        "\n",
        "      # Add the pnorm.\n",
        "      writer.add_scalar(\"pnorm\",\n",
        "        agent.model_parameter_norm(), \n",
        "        global_counter)\n",
        "\n",
        "      # Display the message.\n",
        "      if loss is not None and verbose is True and counter % 20 == 0:\n",
        "        msg = []\n",
        "        msg.append(\"episode = {}\".format(i_episode))\n",
        "        msg.append(\"counter = {}\".format(counter))\n",
        "        msg.append(\"loss = {}\".format(loss))\n",
        "        print(\", \".join(msg))\n",
        "\n",
        "      # Record to the writer.\n",
        "      if loss is not None and verbose is True:\n",
        "        writer.add_scalar(\"loss\",\n",
        "          loss, global_counter)\n",
        "        writer.add_scalar(\"log_loss\", \n",
        "          math.log(loss), global_counter)\n",
        "\n",
        "  # Save the agent's model.\n",
        "  agent.save(AGENT, MODEL)\n",
        "\n",
        "# Close the environment.\n",
        "ipythondisplay.clear_output(wait=True)\n",
        "env.close()\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "optimal value with CVXOPT: 0.024327572958876453\n",
            "[[ 0.99591513]\n",
            " [-0.09029426]\n",
            " [ 0.71434764]]\n",
            "[[1.99995867]]\n",
            "Elapsed time = 0.49361658096313477\n",
            "counter = 20\n",
            "optimal value with CVXOPT: 67.62992900461701\n",
            "[[ 0.1130932 ]\n",
            " [-0.99358438]\n",
            " [ 7.17221104]]\n",
            "[[2.00034355]]\n",
            "Elapsed time = 0.4855687618255615\n",
            "counter = 40\n",
            "optimal value with CVXOPT: 0.2362276367799736\n",
            "[[ 0.90301767]\n",
            " [-0.42960341]\n",
            " [ 6.08316965]]\n",
            "[[1.74766372]]\n",
            "Elapsed time = 0.5818595886230469\n",
            "counter = 60\n",
            "optimal value with CVXOPT: 13.140404307343266\n",
            "[[0.9919026 ]\n",
            " [0.12700093]\n",
            " [3.93841791]]\n",
            "[[-1.99999965]]\n",
            "Elapsed time = 0.5212640762329102\n",
            "counter = 80\n",
            "optimal value with CVXOPT: 0.6886201486338086\n",
            "[[0.99995959]\n",
            " [0.00898949]\n",
            " [4.96132384]]\n",
            "[[-1.99991948]]\n",
            "Elapsed time = 0.5024371147155762\n",
            "counter = 100\n",
            "optimal value with CVXOPT: 13.944639409000832\n",
            "[[0.99069048]\n",
            " [0.13613369]\n",
            " [4.01247424]]\n",
            "[[-2.0000094]]\n",
            "Elapsed time = 0.5004327297210693\n",
            "counter = 120\n",
            "optimal value with CVXOPT: 16.225198630058138\n",
            "[[0.99582757]\n",
            " [0.09125482]\n",
            " [4.83226778]]\n",
            "[[-1.99998579]]\n",
            "Elapsed time = 0.5084481239318848\n",
            "counter = 140\n",
            "optimal value with CVXOPT: 5.328790243345005\n",
            "[[0.99998904]\n",
            " [0.00468276]\n",
            " [3.21676355]]\n",
            "[[-2.00000003]]\n",
            "Elapsed time = 0.557159423828125\n",
            "counter = 160\n",
            "optimal value with CVXOPT: 12.00277366632059\n",
            "[[ 0.59420631]\n",
            " [-0.80431266]\n",
            " [ 6.30055397]]\n",
            "[[-2.00006033]]\n",
            "Elapsed time = 0.5122814178466797\n",
            "counter = 180\n",
            "optimal value with CVXOPT: 8.826762403679481\n",
            "[[ 0.64119391]\n",
            " [-0.7673789 ]\n",
            " [ 6.45108616]]\n",
            "[[-1.99989622]]\n",
            "Elapsed time = 0.5189847946166992\n",
            "counter = 200\n",
            "optimal value with CVXOPT: 41.24901945245621\n",
            "[[-0.75747825]\n",
            " [ 0.6528604 ]\n",
            " [ 1.85723551]]\n",
            "[[-1.99982502]]\n",
            "Elapsed time = 0.41666197776794434\n",
            "counter = 20\n",
            "optimal value with CVXOPT: 129.65648794665833\n",
            "[[-0.87710381]\n",
            " [ 0.48030085]\n",
            " [-2.23559331]]\n",
            "[[-1.99979471]]\n",
            "Elapsed time = 0.40329813957214355\n",
            "counter = 40\n",
            "optimal value with CVXOPT: 152.70642336986836\n",
            "[[-0.99592282]\n",
            " [ 0.09020944]\n",
            " [ 1.45434179]]\n",
            "[[-2.00009743]]\n",
            "Elapsed time = 0.4322044849395752\n",
            "counter = 60\n",
            "optimal value with CVXOPT: 56.69265762248947\n",
            "[[-0.76057314]\n",
            " [ 0.64925226]\n",
            " [ 0.43539197]]\n",
            "[[-2.00020974]]\n",
            "Elapsed time = 0.40363049507141113\n",
            "counter = 80\n",
            "optimal value with CVXOPT: 163.60939490417107\n",
            "[[-0.96706595]\n",
            " [ 0.25452591]\n",
            " [-0.98303591]]\n",
            "[[-1.99984779]]\n",
            "Elapsed time = 0.39362525939941406\n",
            "counter = 100\n",
            "optimal value with CVXOPT: 130.60630158046035\n",
            "[[-0.95770127]\n",
            " [ 0.28776427]\n",
            " [ 0.52185875]]\n",
            "[[-2.00004883]]\n",
            "Elapsed time = 0.4314284324645996\n",
            "counter = 120\n",
            "optimal value with CVXOPT: 129.25263817613833\n",
            "[[-0.93787579]\n",
            " [ 0.34697118]\n",
            " [-0.27161254]]\n",
            "[[-1.99980327]]\n",
            "Elapsed time = 0.41172218322753906\n",
            "counter = 140\n",
            "optimal value with CVXOPT: 133.92797899077016\n",
            "[[-0.96275879]\n",
            " [ 0.2703618 ]\n",
            " [ 0.13022486]]\n",
            "[[-1.99975875]]\n",
            "Elapsed time = 0.46050024032592773\n",
            "counter = 160\n",
            "optimal value with CVXOPT: 103.89391885400696\n",
            "[[-0.96266078]\n",
            " [ 0.27071058]\n",
            " [ 0.16076556]]\n",
            "[[-1.99961157]]\n",
            "Elapsed time = 0.42803120613098145\n",
            "counter = 180\n",
            "optimal value with CVXOPT: 124.55902229229453\n",
            "[[-0.94266823]\n",
            " [ 0.33373133]\n",
            " [ 0.29489017]]\n",
            "[[-1.99990885]]\n",
            "Elapsed time = 0.4206874370574951\n",
            "counter = 200\n",
            "optimal value with CVXOPT: 35.7770799759557\n",
            "[[-0.81510658]\n",
            " [ 0.57931102]\n",
            " [ 0.40461715]]\n",
            "[[-1.99999302]]\n",
            "Elapsed time = 0.41126060485839844\n",
            "counter = 20\n",
            "optimal value with CVXOPT: 118.83961688443898\n",
            "[[-0.96351853]\n",
            " [ 0.26764162]\n",
            " [-0.06069279]]\n",
            "[[-2.00046638]]\n",
            "Elapsed time = 0.44026947021484375\n",
            "counter = 40\n",
            "optimal value with CVXOPT: 114.5042619902638\n",
            "[[-0.9095138 ]\n",
            " [ 0.41567373]\n",
            " [-0.26798899]]\n",
            "[[-2.00012005]]\n",
            "Elapsed time = 0.4010155200958252\n",
            "counter = 60\n",
            "optimal value with CVXOPT: 122.09145632162463\n",
            "[[-0.93596623]\n",
            " [ 0.35208979]\n",
            " [ 0.20796698]]\n",
            "[[-2.00003821]]\n",
            "Elapsed time = 0.4019336700439453\n",
            "counter = 80\n",
            "optimal value with CVXOPT: 104.32733350960132\n",
            "[[-0.88441285]\n",
            " [ 0.46670537]\n",
            " [-0.28290877]]\n",
            "[[-1.99993846]]\n",
            "Elapsed time = 0.4137570858001709\n",
            "counter = 100\n",
            "optimal value with CVXOPT: 126.54109144612288\n",
            "[[-0.95148985]\n",
            " [ 0.30768013]\n",
            " [ 0.11055038]]\n",
            "[[0.18347817]]\n",
            "Elapsed time = 0.47872042655944824\n",
            "counter = 120\n",
            "optimal value with CVXOPT: 120.8664254102679\n",
            "[[-0.92082102]\n",
            " [ 0.38998546]\n",
            " [-0.29107836]]\n",
            "[[-1.99996419]]\n",
            "Elapsed time = 0.4041008949279785\n",
            "counter = 140\n",
            "optimal value with CVXOPT: 116.87172464214078\n",
            "[[-0.92892408]\n",
            " [ 0.37027025]\n",
            " [ 0.28389315]]\n",
            "[[-1.99976126]]\n",
            "Elapsed time = 0.4177730083465576\n",
            "counter = 160\n",
            "optimal value with CVXOPT: 159.1887510513062\n",
            "[[-0.96924637]\n",
            " [ 0.24609242]\n",
            " [-0.63266105]]\n",
            "[[-2.00011397]]\n",
            "Elapsed time = 0.4116053581237793\n",
            "counter = 180\n",
            "optimal value with CVXOPT: 108.15314176948013\n",
            "[[-0.91248191]\n",
            " [ 0.40911706]\n",
            " [ 0.31497592]]\n",
            "[[-2.00001149]]\n",
            "Elapsed time = 0.4029202461242676\n",
            "counter = 200\n",
            "optimal value with CVXOPT: 327.3561957106873\n",
            "[[-0.99985956]\n",
            " [ 0.01675872]\n",
            " [-5.75518486]]\n",
            "[[1.99993679]]\n",
            "Elapsed time = 0.3929874897003174\n",
            "counter = 20\n",
            "optimal value with CVXOPT: 167.54627941589146\n",
            "[[-0.99823726]\n",
            " [-0.05934959]\n",
            " [ 2.1104892 ]]\n",
            "[[-2.00014893]]\n",
            "Elapsed time = 0.42528557777404785\n",
            "counter = 40\n",
            "optimal value with CVXOPT: 296.4344024775511\n",
            "[[-0.84695704]\n",
            " [-0.53166133]\n",
            " [-2.48314331]]\n",
            "[[1.40467204]]\n",
            "Elapsed time = 0.4292736053466797\n",
            "counter = 60\n",
            "optimal value with CVXOPT: 76.06310089491815\n",
            "[[-0.89049779]\n",
            " [ 0.45498757]\n",
            " [ 2.00900666]]\n",
            "[[-1.99995458]]\n",
            "Elapsed time = 0.4110233783721924\n",
            "counter = 80\n",
            "optimal value with CVXOPT: 13.310628268863613\n",
            "[[-0.78178963]\n",
            " [ 0.62354228]\n",
            " [-1.24419234]]\n",
            "[[-1.99993261]]\n",
            "Elapsed time = 0.43325161933898926\n",
            "counter = 100\n",
            "optimal value with CVXOPT: 105.14760196134607\n",
            "[[-0.99856039]\n",
            " [ 0.05363911]\n",
            " [ 0.36152805]]\n",
            "[[-2.00007907]]\n",
            "Elapsed time = 0.5248110294342041\n",
            "counter = 120\n",
            "optimal value with CVXOPT: 70.440814507808\n",
            "[[-0.82184082]\n",
            " [ 0.56971718]\n",
            " [ 0.62656711]]\n",
            "[[-1.99997175]]\n",
            "Elapsed time = 0.4089829921722412\n",
            "counter = 140\n",
            "optimal value with CVXOPT: 139.9723007443844\n",
            "[[-0.934516  ]\n",
            " [ 0.35592111]\n",
            " [-0.95572759]]\n",
            "[[-2.00011204]]\n",
            "Elapsed time = 0.479297399520874\n",
            "counter = 160\n",
            "optimal value with CVXOPT: 127.47484399361684\n",
            "[[-0.95023373]\n",
            " [ 0.31153788]\n",
            " [ 0.36716066]]\n",
            "[[-2.00023802]]\n",
            "Elapsed time = 0.42658090591430664\n",
            "counter = 180\n",
            "optimal value with CVXOPT: 101.2930219668009\n",
            "[[-0.87277662]\n",
            " [ 0.48811983]\n",
            " [-0.39291852]]\n",
            "[[-1.99968387]]\n",
            "Elapsed time = 0.5004429817199707\n",
            "counter = 200\n",
            "optimal value with CVXOPT: 56.42951561937652\n",
            "[[-0.76886073]\n",
            " [ 0.63941627]\n",
            " [ 0.66042501]]\n",
            "[[-1.99994221]]\n",
            "Elapsed time = 0.3963961601257324\n",
            "counter = 20\n",
            "optimal value with CVXOPT: 170.73574201168253\n",
            "[[-0.97351116]\n",
            " [ 0.2286395 ]\n",
            " [-1.04056641]]\n",
            "[[-1.99987622]]\n",
            "Elapsed time = 0.4845542907714844\n",
            "counter = 40\n",
            "optimal value with CVXOPT: 117.30355299684827\n",
            "[[-0.95111636]\n",
            " [ 0.30883274]\n",
            " [ 0.90572598]]\n",
            "[[-1.99992486]]\n",
            "Elapsed time = 0.42318224906921387\n",
            "counter = 60\n",
            "optimal value with CVXOPT: 102.01456853643559\n",
            "[[-0.87651335]\n",
            " [ 0.48137754]\n",
            " [-0.33612654]]\n",
            "[[-1.99982363]]\n",
            "Elapsed time = 0.4915032386779785\n",
            "counter = 80\n",
            "optimal value with CVXOPT: 134.7135382202612\n",
            "[[-0.95757176]\n",
            " [ 0.28819493]\n",
            " [ 0.12811466]]\n",
            "[[-1.99944928]]\n",
            "Elapsed time = 0.4318251609802246\n",
            "counter = 100\n",
            "optimal value with CVXOPT: 90.96978872822667\n",
            "[[-0.86453024]\n",
            " [ 0.5025808 ]\n",
            " [ 0.12517439]]\n",
            "[[-1.99982665]]\n",
            "Elapsed time = 0.4116973876953125\n",
            "counter = 120\n",
            "optimal value with CVXOPT: 137.31642309854243\n",
            "[[-0.94679966]\n",
            " [ 0.32182356]\n",
            " [-0.32722474]]\n",
            "[[-2.00028699]]\n",
            "Elapsed time = 0.4947645664215088\n",
            "counter = 140\n",
            "optimal value with CVXOPT: 102.78015785032727\n",
            "[[-0.90691859]\n",
            " [ 0.42130591]\n",
            " [ 0.45749754]]\n",
            "[[-1.99985994]]\n",
            "Elapsed time = 0.42046117782592773\n",
            "counter = 160\n",
            "optimal value with CVXOPT: 158.14430540262947\n",
            "[[-0.97526707]\n",
            " [ 0.22102973]\n",
            " [-0.25789137]]\n",
            "[[-2.00109755]]\n",
            "Elapsed time = 0.5080103874206543\n",
            "counter = 180\n",
            "optimal value with CVXOPT: 92.119679379281\n",
            "[[-0.86482264]\n",
            " [ 0.50207749]\n",
            " [ 0.0439227 ]]\n",
            "[[-2.00011291]]\n",
            "Elapsed time = 0.4181966781616211\n",
            "counter = 200\n",
            "optimal value with CVXOPT: 27.298509382890195\n",
            "[[-0.41658693]\n",
            " [ 0.90909588]\n",
            " [-2.31740215]]\n",
            "[[1.99957253]]\n",
            "Elapsed time = 0.48315858840942383\n",
            "counter = 20\n",
            "optimal value with CVXOPT: 264.53097302639156\n",
            "[[-0.94857157]\n",
            " [-0.31656275]\n",
            " [-0.38872606]]\n",
            "[[-1.99988961]]\n",
            "Elapsed time = 0.43942832946777344\n",
            "counter = 40\n",
            "optimal value with CVXOPT: 43.36787412542038\n",
            "[[-0.74687273]\n",
            " [ 0.66496701]\n",
            " [ 1.48006177]]\n",
            "[[-1.99998918]]\n",
            "Elapsed time = 0.4927184581756592\n",
            "counter = 60\n",
            "optimal value with CVXOPT: 143.4972042591127\n",
            "[[-0.91189813]\n",
            " [ 0.41041662]\n",
            " [-1.94744212]]\n",
            "[[-2.00064386]]\n",
            "Elapsed time = 0.4062070846557617\n",
            "counter = 80\n",
            "optimal value with CVXOPT: 149.07408886683697\n",
            "[[-0.9947428 ]\n",
            " [ 0.10240489]\n",
            " [ 1.40935858]]\n",
            "[[-1.99998509]]\n",
            "Elapsed time = 0.4704251289367676\n",
            "counter = 100\n",
            "optimal value with CVXOPT: 44.19762243922698\n",
            "[[-0.6395371 ]\n",
            " [ 0.76876023]\n",
            " [-0.80268266]]\n",
            "[[-1.99987748]]\n",
            "Elapsed time = 0.4912395477294922\n",
            "counter = 120\n",
            "optimal value with CVXOPT: 208.49085110995608\n",
            "[[-0.99844418]\n",
            " [-0.05576031]\n",
            " [ 0.0235013 ]]\n",
            "[[-2.00009987]]\n",
            "Elapsed time = 0.4560966491699219\n",
            "counter = 140\n",
            "optimal value with CVXOPT: 52.15077094031076\n",
            "[[-0.7727151 ]\n",
            " [ 0.634753  ]\n",
            " [ 1.15522165]]\n",
            "[[-1.99962075]]\n",
            "Elapsed time = 0.4923844337463379\n",
            "counter = 160\n",
            "optimal value with CVXOPT: 145.47003406293527\n",
            "[[-0.92577207]\n",
            " [ 0.3780821 ]\n",
            " [-1.59344784]]\n",
            "[[-2.00009555]]\n",
            "Elapsed time = 0.3966553211212158\n",
            "counter = 180\n",
            "optimal value with CVXOPT: 143.76564065137313\n",
            "[[-0.984815  ]\n",
            " [ 0.17360707]\n",
            " [ 1.01673669]]\n",
            "[[-1.99987531]]\n",
            "Elapsed time = 0.40778255462646484\n",
            "counter = 200\n",
            "optimal value with CVXOPT: 2.048611809067322\n",
            "[[-0.23040106]\n",
            " [ 0.97309576]\n",
            " [-1.19591028]]\n",
            "[[-1.99981971]]\n",
            "Elapsed time = 0.4257240295410156\n",
            "counter = 20\n",
            "optimal value with CVXOPT: 266.87004868784396\n",
            "[[-0.84143676]\n",
            " [-0.5403556 ]\n",
            " [ 0.71594553]]\n",
            "[[1.99914052]]\n",
            "Elapsed time = 0.5149130821228027\n",
            "counter = 40\n",
            "optimal value with CVXOPT: 1.64280016654701\n",
            "[[-0.45125747]\n",
            " [ 0.8923938 ]\n",
            " [-0.22863863]]\n",
            "[[-1.99999999]]\n",
            "Elapsed time = 0.4126877784729004\n",
            "counter = 60\n",
            "optimal value with CVXOPT: 248.15018318897518\n",
            "[[-0.99630842]\n",
            " [-0.08584603]\n",
            " [-1.49831705]]\n",
            "[[-1.99926553]]\n",
            "Elapsed time = 0.42012667655944824\n",
            "counter = 80\n",
            "optimal value with CVXOPT: 87.49363380702064\n",
            "[[-0.92101611]\n",
            " [ 0.38952449]\n",
            " [ 2.00054904]]\n",
            "[[-2.00000358]]\n",
            "Elapsed time = 0.514441728591919\n",
            "counter = 100\n",
            "optimal value with CVXOPT: 72.87063242413365\n",
            "[[-0.7282527 ]\n",
            " [ 0.68530869]\n",
            " [-1.68120432]]\n",
            "[[-2.00010542]]\n",
            "Elapsed time = 0.48386621475219727\n",
            "counter = 120\n",
            "optimal value with CVXOPT: 180.58392629403252\n",
            "[[-0.9991798 ]\n",
            " [-0.0404935 ]\n",
            " [ 1.19957459]]\n",
            "[[-1.99996658]]\n",
            "Elapsed time = 0.5171341896057129\n",
            "counter = 140\n",
            "optimal value with CVXOPT: 32.72005384415711\n",
            "[[-0.62411838]\n",
            " [ 0.7813298 ]\n",
            " [ 0.33850012]]\n",
            "[[-1.99986439]]\n",
            "Elapsed time = 0.4014701843261719\n",
            "counter = 160\n",
            "optimal value with CVXOPT: 203.73109574510767\n",
            "[[-0.99522414]\n",
            " [ 0.09761611]\n",
            " [-1.21491869]]\n",
            "[[-2.00001088]]\n",
            "Elapsed time = 0.4049966335296631\n",
            "counter = 180\n",
            "optimal value with CVXOPT: 63.191600395805786\n",
            "[[-0.83678548]\n",
            " [ 0.54753087]\n",
            " [ 1.61322718]]\n",
            "[[-2.00003556]]\n",
            "Elapsed time = 0.5046343803405762\n",
            "counter = 200\n",
            "optimal value with CVXOPT: 31.99319310560389\n",
            "[[ 0.63682589]\n",
            " [-0.77100764]\n",
            " [ 3.34096778]]\n",
            "[[2.00021955]]\n",
            "Elapsed time = 0.4969978332519531\n",
            "counter = 20\n",
            "optimal value with CVXOPT: 0.06573711369479918\n",
            "[[-0.36674142]\n",
            " [ 0.93032292]\n",
            " [ 5.52895493]]\n",
            "[[1.99896069]]\n",
            "Elapsed time = 0.5492448806762695\n",
            "counter = 40\n",
            "optimal value with CVXOPT: 27.713408394342995\n",
            "[[0.56930419]\n",
            " [0.82212696]\n",
            " [3.53449187]]\n",
            "[[-1.99998983]]\n",
            "Elapsed time = 0.4959697723388672\n",
            "counter = 60\n",
            "optimal value with CVXOPT: 29.932046459986136\n",
            "[[0.64253663]\n",
            " [0.76625497]\n",
            " [5.00904199]]\n",
            "[[2.00006649]]\n",
            "Elapsed time = 0.49059104919433594\n",
            "counter = 80\n",
            "optimal value with CVXOPT: 31.530856897904005\n",
            "[[0.25571469]\n",
            " [0.96675229]\n",
            " [5.79617427]]\n",
            "[[-1.99988451]]\n",
            "Elapsed time = 0.4968602657318115\n",
            "counter = 100\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VRvHVeyiRoYr",
        "colab_type": "code",
        "outputId": "fa28f1d8-bf4d-4e0b-d579-8f5385ab51c5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 240
        }
      },
      "source": [
        "# ------------- #\n",
        "# -- Figure --- #\n",
        "# ------------- #\n",
        "\n",
        "\n",
        "fig, ax = plt.subplots(2, sharex=True)\n",
        "style = {\"linewidth\":0.75, \"marker\":\".\", \"markersize\":2.0}\n",
        "ax[0].plot(obs[:,0], color=\"r\", **style)\n",
        "ax[0].grid()\n",
        "ax[1].plot(obs[:,1], color=\"r\", **style)\t\n",
        "ax[1].grid()\n",
        "#ax[2].plot(obs[:,2], color=\"r\", **style)\t\n",
        "#ax[2].grid()\n",
        "#ax[3].plot(obs[:,3], color=\"r\", **style)\t\n",
        "#ax[3].grid()\t\t\n",
        "plt.show()\n",
        "plt.close(\"all\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-4b659e33d2aa>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0max\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msubplots\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msharex\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mstyle\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m\"linewidth\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m0.75\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"marker\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\".\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"markersize\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m2.0\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0max\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"r\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mstyle\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'plt' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zlrwm5jVqNJW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}