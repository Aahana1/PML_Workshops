{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "PML_summer_2019_main.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TPGaN_yDR1gf",
        "colab_type": "text"
      },
      "source": [
        "# Data analysis for immediate use:\n",
        "## *a Physics Machine Learning Club bootcamp*\n",
        "\n",
        "\n",
        "You know you need to apply machine learning and deep learning and other data analysis and data visualization methods, yet it’s so new you’ll have to teach yourself. Therefore… you’ve been putting it off.    \n",
        "Our bootcamps focus on presenting examples (a series of jupyter notebooks) that you can adapt directly to your work. We cover a lot of ground in a short period to be as helpful as possible to as many as possible. That should get you started.\n",
        "\n",
        "## Post workshop announcements:\n",
        "\n",
        "*    **Feedback form** Please fill out this feedback form even if you partially attended or only viewed the videos. We will be using results for the continuous improvement of research at WashU  [Link to form: https://forms.gle/UJYkTNTztkSRdrcCA](https://forms.gle/UJYkTNTztkSRdrcCA)\n",
        "*    **Video release** As of 08/16/2019 the videos are not yet edited. This is a simple task and should go quickly. Unedited videos are currently available for all examples presented by James K Johnson (provided the video is complete). For other videos recorded during lecture they will be released by Friday 08/23. For examples which we did not record, videos will be released as soon as they are made. *Make a request! We will expedite the video you need. Email jkjohnson@gmail.com*\n",
        "*    **Join the physics machine learning club** Subscribe to our mailing list!  Follow the link and at the top of the page is the link to join our mailing list. You don't have to complete the form to subscribe, but since you're there anyway, why not? Unsubscribing is easy, there is a link at the bottom of every email.    \n",
        "You'll be informed about future workshops, release of videos, and our regular meeting times and plans. \n",
        "*    **This page is moving** On September 1 this form can only be accessed through the club's github page: https://github.com/jojker/PML_Workshops/blob/master/Summer%202019/PML_summer_2019_main.ipynb We will have a redirect in place, but please update your records.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fUIvBbQbUiQi",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "Each day is focused on a type of goal a researcher might have. Attendance is open to the entire WashU community. We meet from 10 AM to 1 PM with a break in the middle in Cupples I room 115.\n",
        "1.   **Tuesday 07/30 – Best practices:**    \n",
        "Project management, coding style, adapting open source code, parallelization and cluster usage, and Machine Learning nomenclature.\n",
        "1.   **Thursday 08/01 – Turning Images into Data:**    \n",
        "Image preprocessing, image classification, image segmentation, object detection, and tracking, 3D structure from 2D images, pose estimation\n",
        "1.   **Tuesday 08/06 – Turning data in to images:**    \n",
        "Trajectories and point clouds, statistical summaries and 2D maps, tomography, compressed sensing, autoencoders, patch reconstruction\n",
        "1.   **Thursday 08/08 – Identifying, labeling, and classifying:**    \n",
        "Anomaly detection, time series classification, GOFAI classifiers, text classifiers, deep classifiers, clustering, Latent Factors\n",
        "1.   **Tuesday 08/13 – Scientific Insights from learned models:**    \n",
        "Math models (model discovery), dimensionality reduction and unsupervised exploration, time series prediction, abstract representations into images, interpreting large and deep models\n",
        "1.   **Thursday 08/15 – Automated control and design:**    \n",
        "Basic Control Theory, evolving a neural network, reinforcement learning, neural network control, hyper parameter optimization, question answering robots\n",
        "\n",
        "\n",
        "\n",
        "**Prerequisites:**    \n",
        "Know some Python and data analysis concepts. If new to Python, any semester long course in computational methods is adequate.\n",
        "\n",
        "**Post requisites:**    \n",
        "Take an actual course (online or here at WashU) in the fundamentals of machine learning, deep learning, and computational data analysis. It’s OK to do this after starting your project but do it before you make strong research claims about it. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lNb824kF5iAX",
        "colab_type": "text"
      },
      "source": [
        "# The first day of the workshops is upon us! Let's set expectations:\n",
        "\n",
        "Yes, you do need to bring a computer.\n",
        "\n",
        "We are a club engaged in self teaching and neither bound by the ethics nor bogged down by the traditions of formal coursework. Our purpose is to get you started by presenting worked examples that you can quickly adapt to the *first* step of your project. Being the first step we can promise that if it works then you are very very lucky. We are going to show you how to swap out the example data for your own data and a few of the parameters to tweak. We are going to do this many times with many different things. The reason we keep it superficial is because we've been in your shoes. We have the experience of trying to figure out how to implement something and the only clue we have are the names of some functions or some concepts that we *think* we need to use. We know from that experience and trying to learn everything *trying anything* that it is frusterating and slow. Having an example and fooling around with the data, usually makes a few key concepts click, or leads us to the right thread to pull and gets us on our way!\n",
        "\n",
        "We guarantee that we will go too fast! We are trying to get as many people started as possible. This is why we organized each day around a common goal a researcher might have. If you have a well defined project then attending every day, and seeing every example of how to meet every goal will probably be a waste of your time.  You might like it if you are really into data analysis and machine learning, so you are welcome to come to all sessions. This is also why we present overlapping material on different days, and sometimes something basic occurs *after* it's more advanced cousin, (e.g. dimensionality reduction occurs after latent factor analysis). We organized material by research goal, not by conceptual complexity. \n",
        "\n",
        "We will probably get a few things wrong. We are learning by teaching which means this will sometimes be our first project working with some concepts. By calling on the distributed knowledge in the room we hope to be able to answer all your questions but it isn't guaranteed, you get what you pay for. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MFRaS2BW1RYF",
        "colab_type": "text"
      },
      "source": [
        "# Day 1: Best Practices\n",
        "*Tuesday 07/30*\n",
        "\n",
        "This day will be much lighter than other days, we go over some basics and some philosophy. We use this day to communicate about what the rest of the workshops will be like, some tools which will help you implement data analysis, and some intuition behind coding concepts which will help new coders digest some of the information. We don't use it to teach python, hopefully we will always explain everything well enough that anyone can understand but we chose to omit an introduction to python because everything else we teach depends on a user having written at least 500 lines, and hopefully more like 5-10K (about 1 years experience).\n",
        "\n",
        "The order of presentation is in-flux because we have a guest presenter from the High Performance Computing Center. \n",
        "\n",
        "\n",
        "\n",
        "1.   [Data management plans and coding best practices](https://github.com/jojker/PML_Workshops/tree/master/Summer%202019/Day%201%20-%20Best%20practices/Ex%201%20-%20Data%20management%20plans%20y%20coding%20best%20practices/Resources) Presented by Jared Lalmansingh jared.lalmansingh@wustl.edu \n",
        "2.   [Object oriented languages and dynamic programming](https://github.com/jojker/PML_Workshops/tree/master/Summer%202019/Day%201%20-%20Best%20practices/Ex%202%20-%20Object%20Oriented%20languages%20and%20dynamics%20programming/Resources)  Presented by Jared Lalmansingh jared.lalmansingh@wustl.edu \n",
        "1.   [Compute clusters and parallelization](https://github.com/jojker/PML_Workshops/tree/master/Summer%202019/Day%201%20-%20Best%20practices/Ex%203%20-%20Computing%20clusters%2C%20parallelization%20and%20GPUs) + guest presenter (Tobias Malcolm mtobias@wustl.edu ) Presented by James K Johnson jkjohnson@wustl.edu\n",
        "1.    [Using version control](https://github.com/jojker/PML_Workshops/tree/master/Summer%202019/Day%201%20-%20Best%20practices/Ex%204%20-%20Version%20Control)  Presented by Jared Lalmansingh jared.lalmansingh@wustl.edu \n",
        "1.    [Modifying python libraries](https://github.com/jojker/PML_Workshops/tree/master/Summer%202019/Day%201%20-%20Best%20practices/Ex%205%20-%20Modifying%20python%20libraries) Presented by James K Johnson jkjohnson@wustl.edu\n",
        "1.    [Managing your project and your career](https://github.com/jojker/PML_Workshops/tree/master/Summer%202019/Day%201%20-%20Best%20practices/Ex%206%20-%20Managing%20your%20project%20and%20career)  Presented by James K Johnson jkjohnson@wustl.edu\n",
        "1.    [Common quibbles: Machine learning nomenclature](https://github.com/jojker/PML_Workshops/tree/master/Summer%202019/Day%201%20-%20Best%20practices/Ex%207%20-%20Common%20quibbles%20-%20Machine%20Learning%20nomenclature)  Presented by James K Johnson jkjohnson@wustl.edu\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AsOYGuD93Vyj",
        "colab_type": "text"
      },
      "source": [
        "# Day 2: Turning Images into Data\n",
        "*Thursday 08/01*\n",
        "\n",
        "\n",
        "Today we present several examples of tasks that may be similar to those necessary to complete your projects. First we will present basic preprocessing type tasks. These are select to be tasks that are not shown in other examples. Additionally we don't emphasize dimensionality reduction of images, which is perhaps the most interesting preprocessing step. We demonstrate the use of dimensionality reduction in workshops 4 and 5. We do show how to classify images, both with simple DIY neural network and a high-power network built and trained by someone else but used (by you) in a novel context. Classification will be revisited in a later workshop. We show how to label parts of an image and how to track the labeled parts through series of images. This culminates in our presentation about \"DeepLabCut which is software to identify the positions of an organism and it's various body parts throughout a video recording. Lastly we show two completely different ways to get 3D information from 2D images, one is \"structure from motion\" which just means that you have two images that have overlapping fields of view, the other is reconstruction from imaging slices like you might get from a microscope or medical imager. \n",
        "\n",
        "\n",
        "\n",
        "1.   [Image preprocessing folder](https://github.com/jojker/PML_Workshops/tree/master/Summer%202019/Day%202%20-%20Goal%201%20-%20Turning%20Images%20into%20Data/Ex%201%20-%20image%20preprocessing)    -   [NOTEBOOK](https://colab.research.google.com/github/jojker/PML_Workshops/blob/master/Summer%202019/Day%202%20-%20Goal%201%20-%20Turning%20Images%20into%20Data/Ex%201%20-%20image%20preprocessing/image_processing.ipynb)   Presented by James K Johnson jkjohnson@wustl.edu\n",
        "1.   [Image classification and transfer learning folder](https://github.com/jojker/PML_Workshops/tree/master/Summer%202019/Day%202%20-%20Goal%201%20-%20Turning%20Images%20into%20Data/Ex%202%20-%20Multi-label%20classification%20(hopfield%20and%20CNNs))    -   [NOTEBOOK](https://colab.research.google.com/github/jojker/PML_Workshops/blob/master/Summer%202019/Day%202%20-%20Goal%201%20-%20Turning%20Images%20into%20Data/Ex%202%20-%20Multi-label%20classification%20(hopfield%20and%20CNNs)/workshop2_exercise2_character_recognition.ipynb) Presented by Daniel Van Hoesen (d.vanhoesen@wustl.edu)\n",
        "1.   [Image segmentation and tracking folder](https://github.com/jojker/PML_Workshops/tree/master/Summer%202019/Day%202%20-%20Goal%201%20-%20Turning%20Images%20into%20Data/Ex%203%20-%20image%20segmentation%20and%20tracking)    -   [NOTEBOOK](https://colab.research.google.com/github/jojker/PML_Workshops/blob/master/Summer%202019/Day%202%20-%20Goal%201%20-%20Turning%20Images%20into%20Data/Ex%203%20-%20image%20segmentation%20and%20tracking/Day2Goal1Example3_0intro.ipynb) Presented by Wang Shixing wangshixing@wustl.edu\n",
        "1.   [3D structure from overlapping views folder](https://github.com/jojker/PML_Workshops/tree/master/Summer%202019/Day%202%20-%20Goal%201%20-%20Turning%20Images%20into%20Data/Ex%204%20-%203D%20structure%20from%20overlapping%202D%20images)    -   [NOTEBOOK](https://colab.research.google.com/github/jojker/PML_Workshops/blob/master/Summer%202019/Day%202%20-%20Goal%201%20-%20Turning%20Images%20into%20Data/Ex%204%20-%203D%20structure%20from%20overlapping%202D%20images/workshop2_exercise4.ipynb) Presented by Daniel Van Hoesen (d.vanhoesen@wustl.edu)\n",
        "1.   [Object detection and tracking folder](https://github.com/jojker/PML_Workshops/tree/master/Summer%202019/Day%202%20-%20Goal%201%20-%20Turning%20Images%20into%20Data/Ex%205%20-%20object%20detection%20and%20tracking)    -   [NOTEBOOK](https://colab.research.google.com/github/jojker/PML_Workshops/blob/master/Summer%202019/Day%202%20-%20Goal%201%20-%20Turning%20Images%20into%20Data/Ex%205%20-%20object%20detection%20and%20tracking/workshop2_exercise5.ipynb) Presented by Daniel Van Hoesen (d.vanhoesen@wustl.edu)\n",
        "1.   [3D structure from 2D slices folder](https://github.com/jojker/PML_Workshops/tree/master/Summer%202019/Day%202%20-%20Goal%201%20-%20Turning%20Images%20into%20Data/Ex%206%20-%203D%20structure%20from%202D%20slices)    -   [NOTEBOOK](https://colab.research.google.com/github/jojker/PML_Workshops/blob/master/Summer%202019/Day%202%20-%20Goal%201%20-%20Turning%20Images%20into%20Data/Ex%206%20-%203D%20structure%20from%202D%20slices/3D_objects_from_a_stack_of_2D_images.ipynb)  Presented by James K Johnson jkjohnson@wustl.edu\n",
        "1.   [Pose estimation folder](https://github.com/jojker/PML_Workshops/tree/master/Summer%202019/Day%202%20-%20Goal%201%20-%20Turning%20Images%20into%20Data/Ex%207%20-%20Pose%20estimation)    -   [NOTEBOOK](https://colab.research.google.com/github/jojker/PML_Workshops/blob/master/Summer%202019/Day%202%20-%20Goal%201%20-%20Turning%20Images%20into%20Data/Ex%207%20-%20Pose%20estimation/Pose_estimation.ipynb)  Presented by James K Johnson jkjohnson@wustl.edu\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1eF6Z-uVcasw",
        "colab_type": "text"
      },
      "source": [
        "# Day 3: Turning Data into Images\n",
        "*Tuesday 08/06*\n",
        "\n",
        "\n",
        "This day we begin with some very basic examples of plotting. It's important that researchers be able to make attractive plots entirely programatically. By doing it programatically any changes they make to steps of analysis or tweeks to the figures can propagate through to their publication or presentation drafts with little to no steps involving opening an image editor. After these basics we show some machine learning examples. These include compressed sensing, which is a way to create images from sparsely sampled points of light, and is generally useful for breaking the nyquist sampling limit and getting the most information from the fewest data points. We also include the concept of tomography, which is the use of data, not directly in the form of an image, to computationally reconstruct an image. Another included topic is the use of autoencoders, specifically adversarial autoencoders. These algorithms learn ways of reducing large sets of images to some simple statistics or factors. The researcher can then produce fake images simply by generating a small set of random numbers in the range of acceptable values for factors. \n",
        "\n",
        "\n",
        "\n",
        "1.   [Plotting basics folder](https://github.com/jojker/PML_Workshops/tree/master/Summer%202019/Day%203%20-%20Goal%202%20-%20Turning%20Data%20into%20Images/Ex%201%20-%20Trajectories%20and%20Clouds)    -   [NOTEBOOK](https://colab.research.google.com/github/jojker/PML_Workshops/blob/master/Summer%202019/Day%203%20-%20Goal%202%20-%20Turning%20Data%20into%20Images/Ex%201%20-%20Trajectories%20and%20Clouds/Day_3_Ex_1_and_2_Statistical_summaries_and_2D_maps.ipynb)  Presented by Jared Lalmansingh jared.lalmansingh@wustl.edu \n",
        "1.   [General tomography folder](https://github.com/jojker/PML_Workshops/tree/master/Summer%202019/Day%203%20-%20Goal%202%20-%20Turning%20Data%20into%20Images/Ex%203%20-%20General%20Tomography)    -   [NOTEBOOK](https://colab.research.google.com/github/jojker/PML_Workshops/blob/master/Summer%202019/Day%203%20-%20Goal%202%20-%20Turning%20Data%20into%20Images/Ex%203%20-%20General%20Tomography/workshop3_exercise3_tomography.ipynb) Presented by Daniel Van Hoesen (d.vanhoesen@wustl.edu)\n",
        "1.   [Adversarial Autoencoders folder](https://github.com/jojker/PML_Workshops/tree/master/Summer%202019/Day%203%20-%20Goal%202%20-%20Turning%20Data%20into%20Images/Ex%205%20-%20Adversarial%20Autoencoders%20Xia%20Ji)    -   [NOTEBOOK](https://colab.research.google.com/github/jojker/PML_Workshops/blob/master/Summer%202019/Day%203%20-%20Goal%202%20-%20Turning%20Data%20into%20Images/Ex%205%20-%20Adversarial%20Autoencoders%20Xia%20Ji/aae_example.ipynb) Presented by Xia Ji xiaji@wustl.edu \n",
        "1.   [Compressed sensing folder](https://github.com/jojker/PML_Workshops/tree/master/Summer%202019/Day%203%20-%20Goal%202%20-%20Turning%20Data%20into%20Images/Ex%204%20-%20compressed%20sensing)    -   [NOTEBOOK](https://colab.research.google.com/github/jojker/PML_Workshops/blob/master/Summer%202019/Day%203%20-%20Goal%202%20-%20Turning%20Data%20into%20Images/Ex%204%20-%20compressed%20sensing/Compressed_Sensing.ipynb) Presented by James K Johnson jkjohnson@wustl.edu\n",
        "1.   [Computational photography with patches folder](https://github.com/jojker/PML_Workshops/tree/master/Summer%202019/Day%203%20-%20Goal%202%20-%20Turning%20Data%20into%20Images/Ex%206%20-%20Patch%20reconstruction%2C%20denoising%2C%20enhancing)    -   [NOTEBOOK](https://colab.research.google.com/github/jojker/PML_Workshops/blob/master/Summer%202019/Day%203%20-%20Goal%202%20-%20Turning%20Data%20into%20Images/Ex%206%20-%20Patch%20reconstruction%2C%20denoising%2C%20enhancing/Computational_photography_with_image_patches.ipynb) Presented by James K Johnson jkjohnson@wustl.edu\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "4l6yNLEaeX5_"
      },
      "source": [
        "# Day 4: Classifying, Identifying, Labeling\n",
        "*Thursday 08/08*\n",
        "\n",
        "\n",
        "\n",
        "On day 4 we get straight to the point for most people's preconceptions of machine learning. We show basic methods for taking data and identifying key moments in time or key categories. These can be moments or categories the researcher knows about before beginning analysis (supervised learning), or the researcher can discover categories or moments and leverage those in their analysis. Two common tasks a researcher may have is labeling or classifying. These are the same algorithm, but labeling typically means that the researcher is looking for a way to organize data or find things of interest. Classifying usually connotes an intention to output to a separate process, as in an initial step for subsequent analysis or experimentation. \n",
        "\n",
        "\n",
        "\n",
        "1.   [Time series classification folder](https://github.com/jojker/PML_Workshops/tree/master/Summer%202019/Day%204%20-%20Goal%203%20-%20Identifying%2C%20Labeling%2C%20and%20Classifying/Ex%202%20-%20Time%20Series%20Classification)    -   [NOTEBOOK](https://colab.research.google.com/github/jojker/PML_Workshops/blob/master/Summer%202019/Day%204%20-%20Goal%203%20-%20Identifying%2C%20Labeling%2C%20and%20Classifying/Ex%202%20-%20Time%20Series%20Classification/workshop4_exercise2_LSTM.ipynb) Presented by Daniel Van Hoesen (d.vanhoesen@wustl.edu)\n",
        "1.   [Clustering folder](https://github.com/jojker/PML_Workshops/tree/master/Summer%202019/Day%204%20-%20Goal%203%20-%20Identifying%2C%20Labeling%2C%20and%20Classifying/Ex%205%20-%20Clustering)    -   [NOTEBOOK](https://colab.research.google.com/github/jojker/PML_Workshops/blob/master/Summer%202019/Day%204%20-%20Goal%203%20-%20Identifying%2C%20Labeling%2C%20and%20Classifying/Ex%205%20-%20Clustering/MLworkshop_D4E4_ClusteringIntro-KMeansAndBeyond.ipynb) Presented by Hou Yiran yiran@wustl.edu\n",
        "1.   [Factor analysis folder](https://github.com/jojker/PML_Workshops/tree/master/Summer%202019/Day%204%20-%20Goal%203%20-%20Identifying%2C%20Labeling%2C%20and%20Classifying/Ex%207%20-%20Latent%20Factor%20analysis)    -   [NOTEBOOK](https://colab.research.google.com/github/jojker/PML_Workshops/blob/master/Summer%202019/Day%204%20-%20Goal%203%20-%20Identifying%2C%20Labeling%2C%20and%20Classifying/Ex%207%20-%20Latent%20Factor%20analysis/MLworkshop_D4E6_DimReduce_FactorAnalysis.ipynb)  Presented by Hou Yiran yiran@wustl.edu\n",
        "1.   [Text classification folder](https://github.com/jojker/PML_Workshops/tree/master/Summer%202019/Day%204%20-%20Goal%203%20-%20Identifying%2C%20Labeling%2C%20and%20Classifying/Ex%204%20-%20Text%20Classification)    -   [NOTEBOOK](https://colab.research.google.com/github/jojker/PML_Workshops/blob/master/Summer%202019/Day%204%20-%20Goal%203%20-%20Identifying%2C%20Labeling%2C%20and%20Classifying/Ex%204%20-%20Text%20Classification/04_Text_Classification.ipynb) Presented by James K Johnson jkjohnson@wustl.edu\n",
        "1.   [Simple classifiers](https://github.com/jojker/PML_Workshops/tree/master/Summer%202019/Day%204%20-%20Goal%203%20-%20Identifying%2C%20Labeling%2C%20and%20Classifying/Ex%206%20-%20Simple%20classifiers)    -   [NOTEBOOK](https://colab.research.google.com/github/jojker/PML_Workshops/blob/master/Summer%202019/Day%204%20-%20Goal%203%20-%20Identifying%2C%20Labeling%2C%20and%20Classifying/Ex%206%20-%20Simple%20classifiers/Simple_classifiers.ipynb) Presented by James K Johnson jkjohnson@wustl.edu\n",
        "1.   [Image classification folder](https://github.com/jojker/PML_Workshops/tree/master/Summer%202019/Day%204%20-%20Goal%203%20-%20Identifying%2C%20Labeling%2C%20and%20Classifying/Ex%203%20-%20Image%20Classification)    -   [NOTEBOOK](https://github.com/jojker/PML_Workshops/blob/master/Summer%202019/Day%204%20-%20Goal%203%20-%20Identifying%2C%20Labeling%2C%20and%20Classifying/Ex%203%20-%20Image%20Classification/03_Classifying_Cats_and_Dogs.ipynb)  Presented by Jared Lalmansingh jared.lalmansingh@wustl.edu \n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mM2tOvjRi8nu",
        "colab_type": "text"
      },
      "source": [
        "# Day 5: Scientific insights from learned models\n",
        "*Thursday 08/13*\n",
        "\n",
        "\n",
        "On this second to last day of learned models we focus on ways to use machine learning to extract insights about your data. Often an important goal for a scientist is to be able to predict future events, so we include an example on \"simple\" auto-regression based ways to do that as well as deeplearning based methods. The ability to predict does not imply an understanding of core dynamics. For that we turn to symbolic regression and model discovery which are methods to get mathematical models automatically. For the noisy data of complex experiments these often aren't great but for systems that are well isolated they can do quite well. Naturally, understand *does* imply prediction, so we link to deep learning methods which learn the dynamics of a system and can then exploit that for predictions. These dynamics are not represented with equations human-readable equations. There are many versions of human-readable equations that might fit the data so these methods side-step that, but the output of these learned models can be used to augment the data of model discovery methods. \n",
        "\n",
        "Insights are not always about time-series data or mathematical models though! We extend the last session's work with clustering and factor analysis with the broader topic of dimensionality reduction. These methods are useful in many ways. First a researcher can take complex data with many variables and simplify it to view in a 3D plot, whereas they would have to view it in a 7D or 100D or other very high-dimensional space and the human vision system can't do that. Prejudicially, researchers often think that's the only goal of dimensionality reduction. However, dimensionality reduction is fundamental to many other important goes. It can be superior at removing noise, identifying clusters, identifying what items really matter in a set of variables, and the number of dimensions itself is an important metric. If a researcher has two data sources, one can be reduced to 3D and the other to 2D while maintaining the same fraction of information from the original source then the second data source is less complex. This measure, *intrinsic dimensionality* is very useful in guiding future analysis and articulating the limits of a natural system. Different dimensionality reduction algorithms preserve different aspects of the original data source so it isn't always straightforward to make conclusions and if a common method like PCA does not give you the insights you need then another method still might.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "1.   [\"Simple\" timeseries prediction folder](https://github.com/jojker/PML_Workshops/tree/master/Summer%202019/Day%205%20-%20Goal%204%20-%20Scientific%20Insights%20from%20Learned%20Models/Ex%206%20-%20simple%20TS%20prediction)    -   [NOTEBOOK](https://colab.research.google.com/github/jojker/PML_Workshops/blob/master/Summer%202019/Day%205%20-%20Goal%204%20-%20Scientific%20Insights%20from%20Learned%20Models/Ex%206%20-%20simple%20TS%20prediction/workshop5_example6_TimeSeries.ipynb) Presented by Daniel Van Hoesen (d.vanhoesen@wustl.edu)\n",
        "1.   [Dimensionality reduction folder](https://github.com/jojker/PML_Workshops/tree/master/Summer%202019/Day%205%20-%20Goal%204%20-%20Scientific%20Insights%20from%20Learned%20Models/Ex%203%20-%20Dimensionality%20reduction%20and%20unsupervized)    -   [NOTEBOOK](https://colab.research.google.com/github/jojker/PML_Workshops/blob/master/Summer%202019/Day%205%20-%20Goal%204%20-%20Scientific%20Insights%20from%20Learned%20Models/Ex%203%20-%20Dimensionality%20reduction%20and%20unsupervized/MLworkshop_D5E3_DimReduceIntro.ipynb) Presented by Hou Yiran yiran@wustl.edu\n",
        "1.   [Interpreting large models folder](https://github.com/jojker/PML_Workshops/tree/master/Summer%202019/Day%205%20-%20Goal%204%20-%20Scientific%20Insights%20from%20Learned%20Models/Ex%207%20-%20Interpreting%20large%20models)    -   [NOTEBOOK](https://colab.research.google.com/github/jojker/PML_Workshops/blob/master/Summer%202019/Day%205%20-%20Goal%204%20-%20Scientific%20Insights%20from%20Learned%20Models/Ex%207%20-%20Interpreting%20large%20models/Model_interpretations.ipynb) Presented by James K Johnson jkjohnson@wustl.edu\n",
        "1.   [Model discovery folder](https://github.com/jojker/PML_Workshops/tree/master/Summer%202019/Day%205%20-%20Goal%204%20-%20Scientific%20Insights%20from%20Learned%20Models/Ex%202%20-%20Math%20Models%202%20Symbolic%20regression)    -   [NOTEBOOK](https://colab.research.google.com/github/jojker/PML_Workshops/blob/master/Summer%202019/Day%205%20-%20Goal%204%20-%20Scientific%20Insights%20from%20Learned%20Models/Ex%202%20-%20Math%20Models%202%20Symbolic%20regression/Estimating_math_models_of_systems.ipynb)  Presented by James K Johnson jkjohnson@wustl.edu\n",
        "1.   [Deeplearning timeseries prediction folder](https://github.com/jojker/PML_Workshops/tree/master/Summer%202019/Day%205%20-%20Goal%204%20-%20Scientific%20Insights%20from%20Learned%20Models/Ex%204%20-%20Deeplearning%20TS%20prediction)    -   [NOTEBOOK](https://colab.research.google.com/github/jojker/PML_Workshops/blob/master/Summer%202019/Day%205%20-%20Goal%204%20-%20Scientific%20Insights%20from%20Learned%20Models/Ex%204%20-%20Deeplearning%20TS%20prediction/Deep_timeseries_prediction.ipynb) Presented by James K Johnson jkjohnson@wustl.edu"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6oP00h7jpAH5",
        "colab_type": "text"
      },
      "source": [
        "# Day 6:  Automated Control and Design\n",
        "*Thursday 08/15*\n",
        "\n",
        "\n",
        "The hype surounding advances in machine intelligence promotes their ability to complete tasks that humans already do. We've seen how we can exploit machines to do grindingly monotonous statistical inference tasks that humans can't do anyway, but these require humans to design them and get the data prepared. In this workshop we will see how we can offload some of that burden onto the machines also. We will then see how to get machines to interact in the moment. \n",
        "\n",
        "A researcher may want a machine that controls an experimental aparatus, or that manages a simulation in order to keep it exploring the regimes of interest or testing hypothesis (e.g. a fluid dynamics simulation for controlling turbulence, or protein folding). We will see how implement basic methods of control where the error (distance from a desired state) is constantly known. Then we will see how machines learn to keep a system on track to acheiving a desired state, when that state won't occur for several more steps (such as playing a game, moving machinery, or multistep automated chemistry). For anyone in the bio-sciences it may be a pressing goal to have a machine that can interact intelligently with a human, animal, or other agent. We will show how to build a text-based query and response system, showing the potential of machines to be an impartial agent for an interactive experiment.\n",
        "\n",
        "\n",
        "\n",
        "1.   [Basic control theory folder](https://github.com/jojker/PML_Workshops/tree/master/Summer%202019/Day%206%20-%20Goal%205%20-%20Automated%20Control%20and%20Design/Ex%201%20-%20Basic%20Control%20theory)    -   [NOTEBOOK](https://colab.research.google.com/github/jojker/PML_Workshops/blob/master/Summer%202019/Day%206%20-%20Goal%205%20-%20Automated%20Control%20and%20Design/Ex%201%20-%20Basic%20Control%20theory/Ex1_basic_control_theory.ipynb) Presented by Jonathon Monroe (j.monroe@wustl.edu )\n",
        "1.   [Reinforcement learning folder](https://github.com/jojker/PML_Workshops/tree/master/Summer%202019/Day%206%20-%20Goal%205%20-%20Automated%20Control%20and%20Design/Ex%203%20-%20Learn%20Control%20Rules%20with%20Reinforcement)    -   [NOTEBOOK](https://colab.research.google.com/github/jojker/PML_Workshops/blob/master/Summer%202019/Day%206%20-%20Goal%205%20-%20Automated%20Control%20and%20Design/Ex%203%20-%20Learn%20Control%20Rules%20with%20Reinforcement/Ex2_control_with_reinforcement_learning.ipynb) Presented by Jonathon Monroe (j.monroe@wustl.edu )\n",
        "1.   [Hyperparameter optimization folder](https://github.com/jojker/PML_Workshops/tree/master/Summer%202019/Day%206%20-%20Goal%205%20-%20Automated%20Control%20and%20Design/Ex%205%20-%20hyperparameter%20optimization)    -   [NOTEBOOK](https://colab.research.google.com/github/jojker/PML_Workshops/blob/master/Summer%202019/Day%206%20-%20Goal%205%20-%20Automated%20Control%20and%20Design/Ex%205%20-%20hyperparameter%20optimization/Hyperparameter_optimization.ipynb)  Presented by James K Johnson jkjohnson@wustl.edu\n",
        "1.   [Query and response methods folder](https://github.com/jojker/PML_Workshops/tree/master/Summer%202019/Day%206%20-%20Goal%205%20-%20Automated%20Control%20and%20Design/Ex%207%20-%20Question%20answering%20robots)    -   [NOTEBOOK](https://colab.research.google.com/github/jojker/PML_Workshops/blob/master/Summer%202019/Day%206%20-%20Goal%205%20-%20Automated%20Control%20and%20Design/Ex%207%20-%20Question%20answering%20robots/Day_6_Exercise_7_Question_Answering_Robots.ipynb)  Presented by Jared Lalmansingh jared.lalmansingh@wustl.edu \n",
        "1.   [TENTATIVE - Deep model predictive control folder](https://github.com/jojker/PML_Workshops/tree/master/Summer%202019/Day%206%20-%20Goal%205%20-%20Automated%20Control%20and%20Design/Ex%204%20-%20NN%20control%20methods)    -   [NOTEBOOK?](https://colab.research.google.com/github/jojker/PML_Workshops/blob/master/Summer%202019/Day%206%20-%20Goal%205%20-%20Automated%20Control%20and%20Design/Ex%204%20-%20NN%20control%20methods/Ex3_neural_network_control.ipynb)  Presented by Jonathon Monroe (j.monroe@wustl.edu ) \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wfqcg_3WkP3e",
        "colab_type": "text"
      },
      "source": [
        "# About the Physics Machine Learning Club\n",
        "\n",
        "Everyone is welcome, we exist because we know that we will need to teach ourselves machine learning. We meet weekly throughout the school year, usually in the evening. Our meetings are open form, in the past we have done group projects, reached out to local companies, taken MOOCs together, and just came to the same room to work on separate self-education projects in an environment where everyone is welcome to ask questions. The 2019-2020 school year will be lead by Daniel Van Hoesen (d.vanhoesen@wustl.edu) and John Monroe (j.monroe@wustl.edu). They'll help with organizing and make sure there is food and snacks! If you come you can help set the agenda and may find willing helpers to fill a need that the university has. Things we've thought about for the future include having members \"learn by teaching\", meaning someone presents a notebook at every meeting and then the group works through it, or inviting professors for question and answer sessions. \n",
        "\n",
        "Watch this space for updates about the 2019-2020 inaugural meeting and how to participate. \n",
        "\n",
        "\n"
      ]
    }
  ]
}